{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we use the trained model to extract attention and analyze coding and non-coding genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] ME(1157347:139791510296384,MainProcess):2024-12-12-14:42:20.267.318 [mindspore/run_check/_check_version.py:230] Cuda ['10.1', '11.1', '11.6'] version(libcudart*.so need by mindspore-gpu) is not found. Please confirm that the path of cuda is set to the env LD_LIBRARY_PATH, or check whether the CUDA version in wheel package and the CUDA runtime in current device matches. Please refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[ERROR] ME(1157347:139791510296384,MainProcess):2024-12-12-14:42:20.334.103 [mindspore/run_check/_check_version.py:230] Cuda ['10.1', '11.1', '11.6'] version(libcudnn*.so need by mindspore-gpu) is not found. Please confirm that the path of cuda is set to the env LD_LIBRARY_PATH, or check whether the CUDA version in wheel package and the CUDA runtime in current device matches. Please refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(1157347:139791510296384,MainProcess):2024-12-12-14:42:20.336.595 [mindspore/run_check/_check_version.py:98] Can not found cuda libs. Please confirm that the correct cuda version has been installed. Refer to the installation guidelines: https://www.mindspore.cn/install\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import mindspore as ms\n",
    "import mindspore.numpy as mnp\n",
    "import mindspore.scipy as msc\n",
    "import mindspore.dataset as ds\n",
    "from tqdm import tqdm,trange\n",
    "from mindspore import nn,ops\n",
    "from scipy.sparse import csr_matrix as csm\n",
    "from mindspore.amp import FixedLossScaleManager,all_finite,DynamicLossScaleManager\n",
    "from mindspore.train import Model, CheckpointConfig, ModelCheckpoint, LossMonitor\n",
    "from mindspore.context import ParallelMode\n",
    "from mindspore.communication import init, get_rank, get_group_size\n",
    "from mindspore.parallel._utils import _get_parallel_mode\n",
    "from mindspore.common.initializer import initializer, XavierNormal\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from config import Config\n",
    "from model import *\n",
    "from metrics import *\n",
    "from utils import Wrapper,WrapperWithLossScaleCell,load_dist_model\n",
    "from utils import WarmCosineDecay,Adam,AdamWeightDecay,set_weight_decay\n",
    "from data_process import Prepare\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_module(module,filter_tag=[None]):\n",
    "    for param in module.trainable_params():\n",
    "        x=False\n",
    "        for tag in filter_tag:\n",
    "            if tag and tag in param.name:\n",
    "                x=True\n",
    "                break\n",
    "        param.requires_grad = x\n",
    "class Backbone(nn.Cell):\n",
    "    def __init__(self,n_genes,cfg,shard=None,**kwargs):\n",
    "        super().__init__()\n",
    "        self.depth=cfg.enc_nlayers\n",
    "        self.if_cls=cfg.label\n",
    "        self.n_genes=n_genes\n",
    "        self.add_zero=cfg.add_zero and not cfg.pad_zero\n",
    "        self.pad_zero=cfg.pad_zero\n",
    "        # tensor\n",
    "        self.gene_emb=ms.Parameter(\n",
    "            initializer(XavierNormal(0.5),[n_genes+1+(-n_genes-1)%8,cfg.enc_dims])\n",
    "        )\n",
    "        self.cls_token=ms.Parameter(initializer(XavierNormal(0.5),[1,1,cfg.enc_dims]))\n",
    "        self.gene_emb[0,:]=0\n",
    "        # layer\n",
    "        self.value_enc=ValueEncoder(cfg.enc_dims,shard=shard)\n",
    "        self.encoder=nn.CellList([\n",
    "            RetentionLayer(\n",
    "                cfg.enc_dims,cfg.enc_num_heads,cfg.enc_nlayers,\n",
    "                cfg.enc_dropout*i/cfg.enc_nlayers, cfg.lora,\n",
    "                cfg.recompute,shard=shard\n",
    "            )\n",
    "            for i in range(cfg.enc_nlayers)\n",
    "        ])\n",
    "        self.one=P.Ones()\n",
    "        self.zero=P.Zeros()\n",
    "        self.tile=P.Tile()\n",
    "        self.gather=P.Gather()\n",
    "        self.maskmul=P.Mul()\n",
    "        self.posa=P.Add()\n",
    "        self.rsqrt=P.Rsqrt()\n",
    "        self.cat1=P.Concat(1)\n",
    "        self.sum=P.ReduceSum(True)\n",
    "        self.detach=P.StopGradient()\n",
    "    def construct(self,expr,gene,zero_idx):\n",
    "        b,l=gene.shape\n",
    "        gene_emb=self.gather(self.gene_emb,gene,0)\n",
    "        expr_emb,unmask=self.value_enc(expr)\n",
    "        len_scale=self.detach(self.rsqrt(self.sum(zero_idx,-1)-1).reshape(b,1,1,1))\n",
    "\n",
    "        expr_emb=self.posa(gene_emb,expr_emb)\n",
    "        cls_token=self.tile(self.cls_token,(b,1,1))\n",
    "        expr_emb=self.cat1((cls_token,expr_emb))\n",
    "        expr_emb=self.maskmul(expr_emb,zero_idx.reshape(b,-1,1))\n",
    "        mask_pos=zero_idx.reshape(b,1,-1,1)\n",
    "        for i in range(self.depth):\n",
    "            expr_emb=self.encoder[i](\n",
    "                expr_emb,\n",
    "                v_pos=len_scale,\n",
    "                attn_mask=mask_pos\n",
    "            )\n",
    "        return expr_emb\n",
    "class Net(nn.Cell):\n",
    "    def __init__(self,backbone,cfg,shard=None,**kwargs):\n",
    "        super().__init__()\n",
    "        # const\n",
    "        self.num_class=cfg.num_cls\n",
    "        self.extractor=backbone\n",
    "        cls_weight=kwargs.get('cls_weight',np.ones(cfg.num_cls))\n",
    "        self.weight=ms.Tensor(cls_weight,ms.float32)\n",
    "        self.cluster_emb=ms.Parameter(\n",
    "            initializer(XavierNormal(0.5),[cfg.num_cls,cfg.enc_dims])\n",
    "        )\n",
    "        self.query_layer=nn.CellList([\n",
    "            CrossRetentionLayer(cfg.enc_dims,cfg.enc_num_heads,cfg.enc_dropout,False)\n",
    "            for i in range(2)\n",
    "        ])\n",
    "        self.classifier=nn.Dense(cfg.enc_dims,1,has_bias=False)\n",
    "        # operator\n",
    "        self.tile=P.Tile()\n",
    "        self.slice=P.Slice()\n",
    "        self.cat1=P.Concat(1)\n",
    "        self.mm=P.MatMul(transpose_b=True)\n",
    "        self.logsoftmax=P.LogSoftmax(-1)\n",
    "        # loss\n",
    "        self.nll_loss=ops.NLLLoss()\n",
    "        self.logger=ops.ScalarSummary()\n",
    "        self.parallel_mode=_get_parallel_mode()\n",
    "        self.is_distributed = (self.parallel_mode != ParallelMode.STAND_ALONE)\n",
    "        if self.is_distributed:\n",
    "            self.allgather=ops.AllGather()\n",
    "    def forward(self,expr,gene,zero_idx):\n",
    "        emb=self.extractor(expr,gene,zero_idx)\n",
    "        cls_token,expr_emb=emb[:,0],emb[:,1:]\n",
    "        b,l,d=expr_emb.shape\n",
    "        attn_mask=self.slice(zero_idx,(0,1),(-1,-1))\n",
    "        clst_emb=self.cat1((cls_token.reshape(-1,1,d),self.tile(self.cluster_emb.astype(cls_token.dtype).reshape(1,-1,d),(b,1,1))))\n",
    "        for query in self.query_layer:\n",
    "            clst_emb=query(clst_emb,y=expr_emb,attn_mask=attn_mask.reshape(b,1,-1,1))\n",
    "        cls_token,cluster=clst_emb[:,0],clst_emb[:,1:]\n",
    "        labelpred1=self.classifier(cluster).reshape(b,-1)\n",
    "        labelpred2=self.mm(\n",
    "            cls_token,self.cluster_emb.astype(cls_token.dtype)\n",
    "        )\n",
    "        return labelpred1,labelpred2,cls_token\n",
    "    def construct(\n",
    "        self,nonz_data,nonz_gene,zero_idx,label\n",
    "    ):\n",
    "        labelpred1,labelpred2,cls_token=self.forward(\n",
    "            nonz_data,nonz_gene,zero_idx\n",
    "        )\n",
    "        logits1=self.logsoftmax(labelpred1.astype(ms.float32))\n",
    "        logits2=self.logsoftmax(labelpred2.astype(ms.float32))\n",
    "        loss1=self.nll_loss(logits1,label,self.weight.astype(ms.float32))[0]\n",
    "        loss2=self.nll_loss(logits2,label,self.weight.astype(ms.float32))[0]\n",
    "        self.logger('gw_celoss',loss1)\n",
    "        self.logger('cw_celoss',loss2)\n",
    "        loss=loss1+loss2\n",
    "        if self.training:\n",
    "            return loss\n",
    "        else:\n",
    "            if self.is_distributed:\n",
    "                loss=self.allgather(loss).mean()\n",
    "                label=self.allgather(label).reshape(-1,)\n",
    "                labelpred1=self.allgather(labelpred1).reshape(-1,self.num_class)\n",
    "                labelpred2=self.allgather(labelpred2).reshape(-1,self.num_class)\n",
    "            return loss,labelpred1,label,cls_token\n",
    "def read_h5ad(path,fold):\n",
    "    suffix=path.split('.')[-1]\n",
    "    if suffix=='h5ad':\n",
    "        adata=sc.read_h5ad(path)\n",
    "    else:\n",
    "        adata=sc.read_10x_h5(path)\n",
    "    print('origin shape:',adata.shape,len(adata.obs['cell_type'].unique()))\n",
    "    batch=adata.obs.batch.unique()[fold]\n",
    "    train=adata[adata.obs.batch!=batch]\n",
    "    test=adata[adata.obs.batch==batch]\n",
    "    train_type,train_freq=np.unique(train.obs['cell_type'],return_counts=True)\n",
    "    test_type,test_freq=np.unique(test.obs['cell_type'],return_counts=True)\n",
    "    train_type=train_type[train_freq>10]\n",
    "    common_type=np.intersect1d(train_type,test_type)\n",
    "        \n",
    "    data=adata.X.astype(np.float32)\n",
    "    T=adata.X.sum(1)\n",
    "    data=csm(np.round(data/np.maximum(1,T/1e5,dtype=np.float32)))\n",
    "    data.eliminate_zeros()\n",
    "    adata.X=data\n",
    "    \n",
    "    adata=adata[adata.obs['cell_type'].isin(common_type)]\n",
    "    print('filtered shape:',adata.shape,len(adata.obs['cell_type'].unique()))\n",
    "    return adata,batch\n",
    "\n",
    "class SCrna():\n",
    "    def __init__(self,adata,batch,mode='train',prep=True):\n",
    "        self.cls=len(adata.obs['cell_type'].unique())\n",
    "        if mode==\"train\":\n",
    "            adata=adata[adata.obs.batch!=batch]\n",
    "        else:\n",
    "            adata=adata[adata.obs.batch==batch]\n",
    "        self.gene_info=pd.read_csv(f'../csv/expand_gene_info.csv',index_col=0,header=0)\n",
    "        self.geneset={j:i+1 for i,j in enumerate(self.gene_info.index)}\n",
    "        \n",
    "        gene=np.intersect1d(adata.var_names,self.gene_info.index)\n",
    "        adata=adata[:,gene].copy()\n",
    "        adata.obs['cell_type']=adata.obs['cell_type'].astype('category')\n",
    "        label=adata.obs['cell_type'].cat.codes.values\n",
    "        adata.obs['label']=label\n",
    "        if prep:\n",
    "            adata.layers['x_normed']=sc.pp.normalize_total(adata,target_sum=1e4,inplace=False)['X']\n",
    "            adata.layers['x_log1p']=adata.layers['x_normed']\n",
    "            sc.pp.log1p(adata,layer='x_log1p')\n",
    "        if len(adata)==0:\n",
    "            raise Exception('samples are filtered')\n",
    "        self.adata=adata\n",
    "        self.id2label=adata.obs['cell_type'].cat.categories.values\n",
    "        self.gene=np.array([self.geneset[i] for i in self.adata.var_names]).astype(np.int32)\n",
    "        self.cls=len(adata.obs['cell_type'].unique())\n",
    "        self.label=self.adata.obs['label'].values.astype(np.int32)\n",
    "        print(f'{mode} adata:',adata.shape,self.cls,batch)\n",
    "        if prep:\n",
    "            self.data=self.adata.layers['x_log1p'].A.astype(np.float32)\n",
    "        else:\n",
    "            self.data=self.adata.X.astype(np.int32)\n",
    "    def __len__(self):\n",
    "        return len(self.adata)\n",
    "    def __getitem__(self,idx):\n",
    "        data=self.data[idx].reshape(-1)\n",
    "        label=self.label[idx]\n",
    "        return data,self.gene,label\n",
    "def build_dataset(\n",
    "    data,prep,batch,\n",
    "    rank_size=None,\n",
    "    rank_id=None,\n",
    "    drop=True,\n",
    "    shuffle=True\n",
    "):\n",
    "    dataset = ds.GeneratorDataset(\n",
    "        data, \n",
    "        column_names=['data','gene','label'],\n",
    "        shuffle=shuffle,\n",
    "        num_shards=rank_size, \n",
    "        shard_id=rank_id\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        prep.seperate, input_columns=['data'],\n",
    "        output_columns=['data', 'nonz','zero']\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        prep.sample, input_columns=['data','nonz','zero'],\n",
    "        output_columns=['data','nonz','cuted','z_sample','seq_len']\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        prep.compress, input_columns=['data','nonz'],\n",
    "        output_columns=['data','nonz_data', 'nonz']\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        prep.compress, input_columns=['gene','nonz'],\n",
    "        output_columns=['gene','nonz_gene', 'nonz']\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        prep.attn_mask, input_columns=['seq_len'],\n",
    "        output_columns=['zero_idx']\n",
    "    )\n",
    "    dataset = dataset.map(prep.pad_zero, input_columns=['nonz_data'])\n",
    "    dataset = dataset.map(prep.pad_zero, input_columns=['nonz_gene'])\n",
    "    dataset=dataset.project(\n",
    "        columns=['nonz_data','nonz_gene','zero_idx','label']\n",
    "    )\n",
    "    dataset = dataset.batch(\n",
    "        batch,\n",
    "        num_parallel_workers=4, \n",
    "        drop_remainder=drop, \n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 0\n",
    "dist = False\n",
    "enhance = False\n",
    "epoch = 1\n",
    "batch = 1\n",
    "fold = 1\n",
    "data = 'PBMC'\n",
    "\n",
    "datapath = '../dataset/PBMC.h5ad'\n",
    "model_path = \"../checkpoint/PBMC-1-30_1055.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin shape: (18868, 6998) 7\n",
      "filtered shape: (18868, 6998) 7\n",
      "train adata: (16893, 5936) 7 test\n",
      "test adata: (1975, 5936) 7 test\n"
     ]
    }
   ],
   "source": [
    "ms.set_context(\n",
    "    device_target='GPU', \n",
    "    mode=ms.GRAPH_MODE,\n",
    "    device_id=id,\n",
    ")\n",
    "cfg=Config()\n",
    "rank_id = None\n",
    "rank_size = None\n",
    "cfg.nonz_len=2048\n",
    "if dist:\n",
    "    ms.set_auto_parallel_context(\n",
    "        parallel_mode=ms.ParallelMode.DATA_PARALLEL, \n",
    "        parameter_broadcast=True,\n",
    "        gradients_mean=True,\n",
    "        comm_fusion={\"allreduce\": {\"mode\": \"auto\", \"config\": None}},\n",
    "    )\n",
    "    init()\n",
    "    rank_id = get_rank()\n",
    "    rank_size = get_group_size()\n",
    "ms.set_seed(0)\n",
    "adata,batch=read_h5ad(f\"{datapath}/{data}.h5ad\",fold)\n",
    "trainset=SCrna(adata,batch,mode='train')\n",
    "testset=SCrna(adata,batch,mode='test')\n",
    "cfg.enc_dims=1536\n",
    "cfg.enc_nlayers=2\n",
    "cfg.enc_num_heads=48\n",
    "cfg.recompute=False\n",
    "cfg.num_cls=trainset.cls\n",
    "cfg.pad_zero=True\n",
    "cut=None\n",
    "prep=Prepare(\n",
    "    cfg.nonz_len,pad=1,mask_ratio=0,\n",
    "    dw=False,zero_len=None,\n",
    "    cut=cut,random=False\n",
    ")\n",
    "test_loader=build_dataset(\n",
    "    testset,\n",
    "    prep,\n",
    "    1,\n",
    "    drop=True,\n",
    "    shuffle=False,\n",
    "    rank_size=rank_size,\n",
    "    rank_id=rank_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " ['global_step',\n",
       "  'learning_rate',\n",
       "  'beta1_power',\n",
       "  'beta2_power',\n",
       "  'moment1.cluster_emb',\n",
       "  'moment1.query_layer.0.attn1.q_proj.weight',\n",
       "  'moment1.query_layer.0.attn1.k_proj.weight',\n",
       "  'moment1.query_layer.0.attn1.v_proj.weight',\n",
       "  'moment1.query_layer.0.attn1.u_proj.weight',\n",
       "  'moment1.query_layer.0.attn1.o_proj.weight',\n",
       "  'moment1.query_layer.0.attn2.q_proj.weight',\n",
       "  'moment1.query_layer.0.attn2.k_proj.weight',\n",
       "  'moment1.query_layer.0.attn2.v_proj.weight',\n",
       "  'moment1.query_layer.0.attn2.u_proj.weight',\n",
       "  'moment1.query_layer.0.attn2.o_proj.weight',\n",
       "  'moment1.query_layer.0.ffn.u_proj.weight',\n",
       "  'moment1.query_layer.0.ffn.v_proj.weight',\n",
       "  'moment1.query_layer.0.ffn.o_proj.weight',\n",
       "  'moment1.query_layer.0.post_norm1.gamma',\n",
       "  'moment1.query_layer.0.post_norm1.beta',\n",
       "  'moment1.query_layer.0.post_norm2.gamma',\n",
       "  'moment1.query_layer.0.post_norm2.beta',\n",
       "  'moment1.query_layer.0.post_norm3.gamma',\n",
       "  'moment1.query_layer.0.post_norm3.beta',\n",
       "  'moment1.query_layer.1.attn1.q_proj.weight',\n",
       "  'moment1.query_layer.1.attn1.k_proj.weight',\n",
       "  'moment1.query_layer.1.attn1.v_proj.weight',\n",
       "  'moment1.query_layer.1.attn1.u_proj.weight',\n",
       "  'moment1.query_layer.1.attn1.o_proj.weight',\n",
       "  'moment1.query_layer.1.attn2.q_proj.weight',\n",
       "  'moment1.query_layer.1.attn2.k_proj.weight',\n",
       "  'moment1.query_layer.1.attn2.v_proj.weight',\n",
       "  'moment1.query_layer.1.attn2.u_proj.weight',\n",
       "  'moment1.query_layer.1.attn2.o_proj.weight',\n",
       "  'moment1.query_layer.1.ffn.u_proj.weight',\n",
       "  'moment1.query_layer.1.ffn.v_proj.weight',\n",
       "  'moment1.query_layer.1.ffn.o_proj.weight',\n",
       "  'moment1.query_layer.1.post_norm1.gamma',\n",
       "  'moment1.query_layer.1.post_norm1.beta',\n",
       "  'moment1.query_layer.1.post_norm2.gamma',\n",
       "  'moment1.query_layer.1.post_norm2.beta',\n",
       "  'moment1.query_layer.1.post_norm3.gamma',\n",
       "  'moment1.query_layer.1.post_norm3.beta',\n",
       "  'moment1.classifier.weight',\n",
       "  'moment2.cluster_emb',\n",
       "  'moment2.query_layer.0.attn1.q_proj.weight',\n",
       "  'moment2.query_layer.0.attn1.k_proj.weight',\n",
       "  'moment2.query_layer.0.attn1.v_proj.weight',\n",
       "  'moment2.query_layer.0.attn1.u_proj.weight',\n",
       "  'moment2.query_layer.0.attn1.o_proj.weight',\n",
       "  'moment2.query_layer.0.attn2.q_proj.weight',\n",
       "  'moment2.query_layer.0.attn2.k_proj.weight',\n",
       "  'moment2.query_layer.0.attn2.v_proj.weight',\n",
       "  'moment2.query_layer.0.attn2.u_proj.weight',\n",
       "  'moment2.query_layer.0.attn2.o_proj.weight',\n",
       "  'moment2.query_layer.0.ffn.u_proj.weight',\n",
       "  'moment2.query_layer.0.ffn.v_proj.weight',\n",
       "  'moment2.query_layer.0.ffn.o_proj.weight',\n",
       "  'moment2.query_layer.0.post_norm1.gamma',\n",
       "  'moment2.query_layer.0.post_norm1.beta',\n",
       "  'moment2.query_layer.0.post_norm2.gamma',\n",
       "  'moment2.query_layer.0.post_norm2.beta',\n",
       "  'moment2.query_layer.0.post_norm3.gamma',\n",
       "  'moment2.query_layer.0.post_norm3.beta',\n",
       "  'moment2.query_layer.1.attn1.q_proj.weight',\n",
       "  'moment2.query_layer.1.attn1.k_proj.weight',\n",
       "  'moment2.query_layer.1.attn1.v_proj.weight',\n",
       "  'moment2.query_layer.1.attn1.u_proj.weight',\n",
       "  'moment2.query_layer.1.attn1.o_proj.weight',\n",
       "  'moment2.query_layer.1.attn2.q_proj.weight',\n",
       "  'moment2.query_layer.1.attn2.k_proj.weight',\n",
       "  'moment2.query_layer.1.attn2.v_proj.weight',\n",
       "  'moment2.query_layer.1.attn2.u_proj.weight',\n",
       "  'moment2.query_layer.1.attn2.o_proj.weight',\n",
       "  'moment2.query_layer.1.ffn.u_proj.weight',\n",
       "  'moment2.query_layer.1.ffn.v_proj.weight',\n",
       "  'moment2.query_layer.1.ffn.o_proj.weight',\n",
       "  'moment2.query_layer.1.post_norm1.gamma',\n",
       "  'moment2.query_layer.1.post_norm1.beta',\n",
       "  'moment2.query_layer.1.post_norm2.gamma',\n",
       "  'moment2.query_layer.1.post_norm2.beta',\n",
       "  'moment2.query_layer.1.post_norm3.gamma',\n",
       "  'moment2.query_layer.1.post_norm3.beta',\n",
       "  'moment2.classifier.weight'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone=Backbone(len(trainset.geneset),cfg,shard=None)\n",
    "model=Net(backbone,cfg,shard=None)\n",
    "\n",
    "model_path = \"../checkpoint/PBMC-1-30_1055.ckpt\"\n",
    "ms.load_param_into_net(model, ms.load_checkpoint(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retrieve CellFM's attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1975 [00:00<?, ?it/s][ERROR] CORE(1157347,7f23bf505740,python):2024-12-12-14:42:52.324.374 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1157347/1715952173.py]\n",
      "[ERROR] CORE(1157347,7f23bf505740,python):2024-12-12-14:42:52.324.414 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1157347/1715952173.py]\n",
      "[ERROR] CORE(1157347,7f23bf505740,python):2024-12-12-14:42:52.325.316 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1157347/1715952173.py]\n",
      "100%|██████████| 1975/1975 [04:14<00:00,  7.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "attention_map = {}\n",
    "for i in range(cfg.num_cls):\n",
    "    attention_map[i] = defaultdict(list)\n",
    "\n",
    "attention_genes = {}\n",
    "for i in range(cfg.num_cls):\n",
    "    attention_genes[i] = []\n",
    "\n",
    "\n",
    "pred_list = []\n",
    "label_list = []\n",
    "\n",
    "for idx, data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "    nonz_data,nonz_gene,zero_idx,label = data\n",
    "    emb = model.extractor(nonz_data, nonz_gene, zero_idx)\n",
    "    cls_token,expr_emb=emb[:,0],emb[:,1:]\n",
    "    b,l,d=expr_emb.shape\n",
    "    attn_mask=model.slice(zero_idx,(0,1),(-1,-1))\n",
    "    clst_emb=model.cat1((cls_token.reshape(-1,1,d),model.tile(model.cluster_emb.astype(cls_token.dtype).reshape(1,-1,d),(b,1,1))))\n",
    "    for query in model.query_layer[:-1]:\n",
    "        clst_emb=query(clst_emb,y=expr_emb,attn_mask=attn_mask.reshape(b,1,-1,1))\n",
    "    attn2 = model.query_layer[-1].attn2\n",
    "    q,k,v,u = attn2.qkvu_compute(clst_emb, expr_emb)\n",
    "\n",
    "    _,l1,d=q.shape\n",
    "    _,l2,d=k.shape\n",
    "    Q = attn2.transpose1(P.Reshape()(q,(-1,l1,48,attn2.head_dims)),(0,2,1,3))\n",
    "    K = attn2.transpose1(P.Reshape()(k,(-1,l2,48,attn2.head_dims)),(0,2,1,3))\n",
    "    V = attn2.transpose1(P.Reshape()(v,(-1,l2,48,attn2.head_dims)),(0,2,1,3))\n",
    "    U = attn2.transpose1(P.Reshape()(u,(-1,l1,48,attn2.head_dims)),(0,2,1,3))\n",
    "    \n",
    "    Q=attn2.kernelQ(Q)\n",
    "    K=attn2.kernelK(K)\n",
    "    U=attn2.kernelU(U)\n",
    "    if attn_mask is not None:\n",
    "        K=attn2.maskmul(K,attn_mask.reshape(b,1,-1,1))\n",
    "    Q=attn2.div(Q,attn2.scale)\n",
    "    K=attn2.div(K,attn2.scale)\n",
    "\n",
    "    attn_scores = Q @ K.permute(0,1,3,2)\n",
    "\n",
    "    attn_scores = attn_scores[:, :, 0, :]\n",
    "\n",
    "    order = ms.ops.argsort(attn_scores, axis=-1)\n",
    "    attn_scores = ms.ops.argsort(order, axis=-1).astype(ms.float32) / 2048\n",
    "\n",
    "    reduce_mean = ops.ReduceMean(keep_dims=False)\n",
    "    attn_scores = reduce_mean(attn_scores, axis=1)\n",
    "\n",
    "\n",
    "    attn_scores = attn_scores.asnumpy()[0]\n",
    "\n",
    "    clst_emb=model.query_layer[-1](clst_emb,y=expr_emb,attn_mask=attn_mask.reshape(b,1,-1,1))\n",
    "    cls_token,cluster=clst_emb[:,0],clst_emb[:,1:]\n",
    "    labelpred1=model.classifier(cluster).reshape(b,-1)\n",
    "\n",
    "    pred_list.append(labelpred1)\n",
    "    label_list.append(label)\n",
    "\n",
    "    cell_type = label.asnumpy()[0]\n",
    "    gene_names = nonz_gene.asnumpy()[0]\n",
    "\n",
    "\n",
    "    for idx, gene_idx in enumerate(gene_names):\n",
    "        attention_map[cell_type][gene_idx].append(attn_scores[idx])\n",
    "\n",
    "\n",
    "pred_list = ops.operations.Concat(axis=0)(pred_list)\n",
    "label_list = ops.operations.Concat(axis=0)(label_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select genes with high attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(cfg.num_cls):\n",
    "    for k in attention_map[i]:\n",
    "        attention_map[i][k] = sum(attention_map[i][k]) / len(attention_map[i][k])\n",
    "\n",
    "for i in range(cfg.num_cls):\n",
    "    attention_map[i] = sorted(attention_map[i].items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "\n",
    "# attention_map[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../csv/expand_gene_info.csv',index_col=0,header=0)\n",
    "\n",
    "geneset={i+1:j for i,j in enumerate(df.index)}\n",
    "feature = dict(zip(df.index, df['feature']))\n",
    "\n",
    "id2label=adata.obs['cell_type'].cat.categories.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD4T\n",
      "encoded gene: ['CDO1', 'FAM50B', 'RAPGEF6', 'CCDC51', 'MAP9', 'PRR12', 'SMNDC1', 'PMM2', 'DPM3', 'ZNF599', 'TMTC3', 'CNPY4', 'F5', 'PIAS2', 'ZNF771', 'PARN', 'IL18R1', 'PCP2', 'WARS2', 'SHPRH', 'SEC14L2', 'TPRG1', 'ZNF580', 'PGAM5', 'EPS15L1', 'MAGEE1', 'RMDN3', 'CBL', 'NMB', 'HERC2', 'FBLN5', 'MYBL1', 'GJB6', 'NIFK', 'TBL1X', 'HSPH1', 'TXLNG', 'RPS6KB1', 'RAB11FIP4', 'SMC1A', 'TOMM34', 'CENPE', 'CLEC11A', 'NR2C2AP', 'LTN1', 'ZNF256', 'COQ7', 'CRY2', 'GNB1L', 'SCCPDH', 'CEACAM21', 'ECE2', 'HIRIP3', 'ZBTB48', 'TRIM41', 'XXYLT1', 'ABCB8', 'ZNF700', 'PSPH', 'TUBB1', 'TMEM129', 'STK19', 'UBASH3A', 'ZBTB2', 'ASPSCR1', 'SPP1', 'PJA1', 'PDLIM2', 'DEF6', 'PEX6', 'FLT1', 'PCIF1', 'GDPD5', 'ATG9B', 'ST6GALNAC1', 'PHF6', 'MLLT11', 'ATG9A', 'ELOVL4', 'SFMBT2', 'PICK1', 'ZNF85', 'LIN9', 'NQO1', 'ATR', 'SEL1L', 'NCKIPSD', 'FCGR3A', 'ZMYM2', 'PRC1', 'RCC1', 'HBG2', 'STXBP4', 'RORC', 'MAP2K3']\n",
      "non encoded gene: ['MIR29A', 'IQCH-AS1', 'CD27-AS1', 'ENTPD1-AS1', 'ZNF337-AS1']\n",
      "--------------\n",
      "CD14+Mono\n",
      "encoded gene: ['TUBB1', 'RMDN3', 'TMTC3', 'MAP9', 'CCDC51', 'CENPE', 'TOMM34', 'COQ7', 'PICK1', 'RAPGEF6', 'ZNF580', 'FAM50B', 'FBLN5', 'TBL1X', 'FCGR3A', 'KLHL7', 'PEX6', 'NUDT2', 'ZNF331', 'TMCO6', 'ACTR1B', 'RAB3GAP2', 'TNF', 'F5', 'SMARCAL1', 'RANBP2', 'TMEM129', 'TXLNG', 'ST6GALNAC1', 'NOP14', 'DPM3', 'ZNF780B', 'ZMYM2', 'TCP11L1', 'IPO11', 'MKS1', 'SMNDC1', 'COG1', 'CCDC22', 'CDKN1C', 'KLRC1', 'GADD45G', 'NECAP1', 'UBE2D4', 'FAM136A', 'HIRIP3', 'PKIB', 'LTN1', 'IL19', 'ASNS', 'UTP14A', 'ZNF493', 'NELFE', 'XYLT1', 'NIFK', 'ZNF771', 'PSPH', 'PTPMT1', 'THAP5', 'ULBP2', 'ALAS2', 'TRIM11', 'TTI1', 'LIN9', 'ZBTB48', 'SLC37A1', 'FSCN1', 'FABP5', 'NR2C2AP', 'GLS', 'DHRS13', 'ST7', 'POGZ', 'SLC25A4', 'OPA1', 'NSDHL', 'TPST1', 'ACD', 'HSPH1', 'C5orf22', 'RINL', 'RBFA', 'MSANTD4', 'RAB11FIP4', 'DGKQ', 'PSMD10', 'FKBP7', 'CARD11', 'ZNF543', 'ZNF559', 'STAG1', 'ORC5', 'ZNF235', 'NUP54', 'TAF6', 'ZNF222', 'GPR155']\n",
      "non encoded gene: ['MIR29A', 'LINC01004', 'HOTAIRM1']\n",
      "--------------\n",
      "B\n",
      "encoded gene: ['F5', 'TUBB1', 'CNPY4', 'HIRIP3', 'CCDC51', 'RAB11FIP4', 'ZNF580', 'RAPGEF6', 'CHAC1', 'PMM2', 'FAM50B', 'NOP14', 'THRA', 'PIAS2', 'TMEM67', 'LTN1', 'ZNF599', 'RASL11A', 'ABHD5', 'NIFK', 'PICK1', 'NUDT2', 'MLYCD', 'COQ7', 'ZRANB3', 'TOMM34', 'SPIN1', 'SMNDC1', 'PRR12', 'BNIPL', 'TMEM129', 'POLR1E', 'RAB3GAP2', 'PSPH', 'GPLD1', 'PIM1', 'MAP9', 'ZBTB48', 'UXS1', 'IL19', 'NUP88', 'ZMYM2', 'FBLN5', 'PTPMT1', 'RRAGB', 'CKAP2', 'LIN9', 'RCC1', 'NUP54', 'THAP5', 'TBL1X', 'GNG7', 'GPR75-ASB3', 'NSDHL', 'ZDBF2', 'PEX6', 'WARS2', 'FAM135A', 'EPS15L1', 'ECE2', 'TXLNG', 'MAP2K3', 'C11orf71', 'ZNF43', 'ALAD', 'SMARCAL1', 'ELOVL4', 'YLPM1', 'PPIL1', 'NME4', 'IL18R1', 'ZNF771', 'DHRS13', 'TMEM116', 'C1orf109', 'GLS', 'TMED7', 'TIGD7', 'DPM3', 'BTLA', 'XYLT1', 'HSPH1', 'ZNF700', 'KMT2A', 'RMDN3', 'RIMBP3C', 'SURF6', 'EAF2', 'SEMA7A', 'SFMBT2', 'TMEM9', 'TOE1', 'NELFE', 'UBE2O', 'MNAT1']\n",
      "non encoded gene: ['ZNF674-AS1', 'ZBTB20-AS1', 'ZNF337-AS1', 'MIR29A', 'ENTPD1-AS1']\n",
      "--------------\n",
      "CD8T\n",
      "encoded gene: ['CCDC51', 'RAPGEF6', 'SMNDC1', 'MAP9', 'GMPPB', 'FAM50B', 'SEC14L2', 'TBL1X', 'TXLNG', 'EPS15L1', 'IL18R1', 'PRR12', 'CBL', 'ZNF256', 'TMTC3', 'ZNF700', 'PDLIM2', 'CDKN1C', 'DPM3', 'ALAS2', 'PIAS2', 'ZNF599', 'TMEM129', 'CNPY4', 'FBLN5', 'PMM2', 'SHPRH', 'UBASH3A', 'WARS2', 'NMB', 'RMDN3', 'SMC1A', 'LTN1', 'TOMM34', 'MLLT11', 'GNB1L', 'COQ7', 'ECE2', 'HSPH1', 'RCC1', 'TRIB3', 'COG1', 'RANBP2', 'GADD45G', 'RAB11FIP4', 'NIFK', 'TPRG1', 'GTPBP10', 'STK19', 'ZNF506', 'RAB3GAP2', 'COG3', 'PJA1', 'ZBTB2', 'ELOVL4', 'UXS1', 'RPS6KB1', 'CRY2', 'PICK1', 'CENPE', 'XXYLT1', 'EGR1', 'PDE4D', 'ANKRD27', 'PPIL1', 'DLK2', 'HERC2', 'ALAD', 'NUDT2', 'ZNF85', 'NR2C2AP', 'EGR4', 'CLEC11A', 'TRMT13', 'TOE1', 'ZNF568', 'PTGDR', 'SLC25A46', 'TMEM9', 'RBM43', 'TMEM67', 'ASPSCR1', 'ITK', 'ATR', 'ZMYM4', 'TMEM135', 'FCGR3A', 'TBXA2R', 'ZNF222', 'CHAC1', 'ZNF540', 'URI1', 'ARMC5', 'STAT5B', 'HIRIP3', 'TRIM59', 'ZMYM2']\n",
      "non encoded gene: ['ENTPD1-AS1', 'HOTAIRM1', 'ZNF674-AS1']\n",
      "--------------\n",
      "NK\n",
      "encoded gene: ['MAP9', 'TUBB1', 'SMNDC1', 'CCDC51', 'FAM50B', 'ZNF700', 'ZNF580', 'HIRIP3', 'DPM3', 'TMEM129', 'FBLN5', 'SLC37A1', 'GNB1L', 'TNF', 'RMDN3', 'CBL', 'EPS15L1', 'UBASH3A', 'LTN1', 'MYBL1', 'TOE1', 'NMB', 'PGBD4', 'LIN9', 'HSPH1', 'TBL1X', 'RTKN2', 'IRAK1BP1', 'MAGEE1', 'RAB3GAP2', 'ZNF256', 'ZNF347', 'TXLNG', 'ZSCAN29', 'RAB11FIP4', 'TOMM34', 'ZRANB3', 'DUS4L', 'SMC1A', 'PEX6', 'RANBP2', 'SPICE1', 'PTPRM', 'TRMT13', 'GNG7', 'COG5', 'ZNF506', 'NIFK', 'NAP1L3', 'ECE2', 'PIAS2', 'WDR3', 'SEC14L2', 'PSPH', 'COQ7', 'SHPRH', 'FCGR3A', 'SLC14A1', 'CBLL1', 'PICK1', 'XXYLT1', 'CNPY4', 'TIGD7', 'ASNS', 'UXS1', 'IL18R1', 'ITK', 'WARS2', 'NUP88', 'TMEM67', 'NUDT2', 'ALAD', 'STXBP4', 'ELOVL4', 'C5orf22', 'PIM1', 'ZNF331', 'ZNF780A', 'TPRG1', 'ATMIN', 'RASA2', 'MLLT11', 'OTUD4', 'GZMA', 'RPS6KB1', 'PCIF1', 'PPIL1', 'GSTCD', 'MED7', 'FAM136A', 'GPR75-ASB3', 'POLB', 'ABCB8', 'MESP1', 'ZNF781', 'SMARCA2', 'MXI1', 'ZMYM2']\n",
      "non encoded gene: ['ZBTB20-AS1', 'HOTAIRM1']\n",
      "--------------\n",
      "FCGR3A+Mono\n",
      "encoded gene: ['CDO1', 'TUBB1', 'PRR12', 'CENPE', 'TMTC3', 'RMDN3', 'ZNF580', 'PICK1', 'MAP9', 'TBL1X', 'COQ7', 'CNPY4', 'LRRC36', 'ZNF331', 'FBLN5', 'FLT1', 'TOMM34', 'CCDC51', 'NUDT2', 'SLFN12L', 'FCGR3A', 'RAB3GAP2', 'TXLNG', 'PEX6', 'ST6GALNAC1', 'KLHL7', 'TNF', 'ZNF568', 'ZMYM2', 'RANBP2', 'DPM3', 'ULBP2', 'ZNF664', 'RCC1', 'TMEM129', 'LTN1', 'SMNDC1', 'FAM136A', 'CIPC', 'PTPMT1', 'TCP11L1', 'ZNF584', 'PKIB', 'UBR1', 'UTP14A', 'SLC52A1', 'PRIMPOL', 'TTI1', 'EPHX2', 'HERC2', 'DUS4L', 'HSPH1', 'NELFE', 'COG1', 'GADD45G', 'ZNF700', 'GZMA', 'TMEM116', 'ZNF780B', 'SMARCAL1', 'THAP5', 'MIPEP', 'ACTR1B', 'ZNF493', 'PGBD4', 'KLRC1', 'TTLL1', 'ALAS2', 'POGZ', 'MLLT11', 'ZNF443', 'SURF6', 'NIFK', 'NECAP1', 'NR2C2AP', 'TRIM11', 'TMCO6', 'ECE2', 'FABP5', 'WDR83', 'MT1G', 'TIGD7', 'PIK3R4', 'ZBTB48', 'GNB1L', 'CDKN1C', 'AUH', 'F5', 'PIAS2', 'NOP14', 'PRRT2', 'CCDC22', 'TPST1', 'WDR53', 'GTPBP10', 'PHC3']\n",
      "non encoded gene: ['MIR29A', 'ZNF337-AS1', 'LINC01004', 'ENTPD1-AS1']\n",
      "--------------\n",
      "Dendritic\n",
      "encoded gene: ['MAP9', 'TOMM34', 'ZNF580', 'RMDN3', 'FBLN5', 'TMTC3', 'FAM50B', 'PICK1', 'TBL1X', 'TXLNG', 'KLRC1', 'CCDC51', 'COQ7', 'TMEM129', 'ZNF331', 'RCC1', 'RAB3GAP2', 'ZBTB4', 'KLHL7', 'FCGR3A', 'RAB11FIP4', 'TNF', 'SURF6', 'ATP6V0A4', 'NECAP1', 'GMPPB', 'ACTR1B', 'SIT1', 'ZNF771', 'NOP14', 'TCP11L1', 'HERC2', 'DPM3', 'PTPMT1', 'NIFK', 'NELFE', 'CCDC22', 'ZBTB48', 'LTN1', 'GADD45G', 'SMNDC1', 'FAM136A', 'RANBP2', 'TMEM116', 'UBASH3A', 'PSMD10', 'TACC3', 'ZNF568', 'PKIB', 'ALAD', 'WDR5B', 'WDR83', 'GNG7', 'GLS', 'EPHX2', 'XYLT1', 'FSCN1', 'TRIM66', 'SUPV3L1', 'HSPH1', 'NR2C2AP', 'ZC2HC1A', 'SMARCAL1', 'CENPV', 'NUP54', 'RRAGB', 'GNB1L', 'NSDHL', 'TPST1', 'POGZ', 'PIK3R4', 'PRIMPOL', 'IL19', 'WDR53', 'ATMIN', 'CREB3L4', 'MSANTD4', 'ZNF823', 'PIAS2', 'UBR1', 'OPA1', 'FABP5', 'NEDD1', 'TTI1', 'ZNF420', 'TRIM11', 'ZNF222', 'NBPF11', 'PRRT2', 'PRPS1', 'ZNF445', 'SH2D1B', 'ZNF83', 'KBTBD7', 'ZNF383', 'ANO9', 'FKBP7', 'ACD']\n",
      "non encoded gene: ['MIR29A', 'ENTPD1-AS1']\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "topk = 100\n",
    "for i in range(cfg.num_cls):\n",
    "    print(id2label[i])\n",
    "    topk_gene = [gene[0] for  gene in attention_map[i][:topk]]\n",
    "    topk_gene = [geneset[gene] for gene in topk_gene]\n",
    "    non_encoded_gene, encoded_gene = [], []\n",
    "    for gene in topk_gene:\n",
    "        if feature[gene] != 'protein coding':\n",
    "            non_encoded_gene.append(gene)\n",
    "        else:\n",
    "            encoded_gene.append(gene)\n",
    "    print('encoded gene:', encoded_gene)\n",
    "    print('non encoded gene:', non_encoded_gene)\n",
    "    print('--------------')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
