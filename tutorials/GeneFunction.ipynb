{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86f8778-f555-4ff6-bd6e-8b266dc5be30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:29:42.083103Z",
     "iopub.status.busy": "2024-06-28T13:29:42.082778Z",
     "iopub.status.idle": "2024-06-28T13:29:46.579747Z",
     "shell.execute_reply": "2024-06-28T13:29:46.578973Z",
     "shell.execute_reply.started": "2024-06-28T13:29:42.083064Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import pickle as pk\n",
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "import mindspore.numpy as mnp\n",
    "import mindspore.scipy as msc\n",
    "import mindspore.dataset as ds\n",
    "from tqdm import tqdm,trange\n",
    "from mindspore import nn,ops\n",
    "from scipy.sparse import csr_matrix as csr\n",
    "from mindspore.ops import operations as P\n",
    "from mindspore.amp import FixedLossScaleManager,all_finite,DynamicLossScaleManager\n",
    "from mindspore.train import Model, CheckpointConfig, ModelCheckpoint, LossMonitor, Accuracy\n",
    "from mindspore.context import ParallelMode\n",
    "from mindspore.communication import init, get_rank, get_group_size\n",
    "from mindspore.parallel._utils import _get_parallel_mode\n",
    "from mindspore.common.initializer import initializer, XavierNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c6a4d7-98ca-4a43-9c6b-8da9bbda1ab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:29:46.581635Z",
     "iopub.status.busy": "2024-06-28T13:29:46.581243Z",
     "iopub.status.idle": "2024-06-28T13:29:46.608008Z",
     "shell.execute_reply": "2024-06-28T13:29:46.607477Z",
     "shell.execute_reply.started": "2024-06-28T13:29:46.581617Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "from utils import Wrapper\n",
    "from config import Config\n",
    "from metrics import annote_metric\n",
    "from genefunc_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad08af90-72b0-4d17-b32a-43494d1f1e5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:29:46.608906Z",
     "iopub.status.busy": "2024-06-28T13:29:46.608715Z",
     "iopub.status.idle": "2024-06-28T13:29:46.615742Z",
     "shell.execute_reply": "2024-06-28T13:29:46.615293Z",
     "shell.execute_reply.started": "2024-06-28T13:29:46.608889Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SCrna():\n",
    "    def __init__(self,path,data,fold,mode):\n",
    "        self.mode=mode\n",
    "        adata=sc.read_h5ad(f'{path}/t123.h5ad')\n",
    "        self.gene_info=pd.read_csv(f'../csv/gene_info.csv',index_col=0,header=0)\n",
    "        common_gene=np.intersect1d(adata.var_names,self.gene_info.index)\n",
    "        self.adata=adata[:,common_gene].copy()\n",
    "        gene=self.adata.var[self.adata.var[f'train_{data}']>-1]\n",
    "        idx=gene[f'train_{data}']==fold\n",
    "        self.geneset={j:i+1 for i,j in enumerate(self.gene_info.index)}\n",
    "        if mode=='train':\n",
    "            self.gene=np.array([self.geneset[i] for i in gene[~idx].index]).astype(np.int32)\n",
    "            self.label=gene[f'{data}'][~idx].values\n",
    "        else:\n",
    "            self.gene=np.array([self.geneset[i] for i in gene[idx].index]).astype(np.int32)\n",
    "            self.label=gene[f'{data}'][idx].values\n",
    "    def __len__(self):\n",
    "        return len(self.gene)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.gene[idx],self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78fa6c15-99cd-4ba0-8989-760f2c6da7e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:29:46.616620Z",
     "iopub.status.busy": "2024-06-28T13:29:46.616462Z",
     "iopub.status.idle": "2024-06-28T13:29:46.620004Z",
     "shell.execute_reply": "2024-06-28T13:29:46.619520Z",
     "shell.execute_reply.started": "2024-06-28T13:29:46.616606Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataset(\n",
    "    data,batch,\n",
    "    mask_rate=0.2,\n",
    "    drop=True,\n",
    "    shuffle=True,\n",
    "    rank_size=None,\n",
    "    rank_id=None,\n",
    "):\n",
    "    dataset = ds.GeneratorDataset(\n",
    "        data, \n",
    "        column_names=[\"gene\",'label'],\n",
    "        shuffle=shuffle,\n",
    "        num_shards=rank_size, \n",
    "        shard_id=rank_id\n",
    "    )\n",
    "    dataset = dataset.batch(\n",
    "        batch,\n",
    "        num_parallel_workers=4, \n",
    "        drop_remainder=drop, \n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "829338bf-b7ce-45e2-82f5-801021fc9970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:29:46.620716Z",
     "iopub.status.busy": "2024-06-28T13:29:46.620563Z",
     "iopub.status.idle": "2024-06-28T13:29:46.623555Z",
     "shell.execute_reply": "2024-06-28T13:29:46.623129Z",
     "shell.execute_reply.started": "2024-06-28T13:29:46.620703Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms.set_context(\n",
    "    device_target='Ascend', \n",
    "    mode=ms.GRAPH_MODE,\n",
    "    device_id=0,\n",
    ")\n",
    "ms.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56a1cf80-0848-499c-b8bc-3e96da1b8217",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:29:46.624238Z",
     "iopub.status.busy": "2024-06-28T13:29:46.624086Z",
     "iopub.status.idle": "2024-06-28T13:30:13.579805Z",
     "shell.execute_reply": "2024-06-28T13:30:13.578493Z",
     "shell.execute_reply.started": "2024-06-28T13:29:46.624225Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "para=ms.load_checkpoint(\"../weights/base_weight.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdefdaa0-7e38-48e6-9891-990f5aad0e84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:30:13.581824Z",
     "iopub.status.busy": "2024-06-28T13:30:13.581614Z",
     "iopub.status.idle": "2024-06-28T13:30:48.161854Z",
     "shell.execute_reply": "2024-06-28T13:30:48.160852Z",
     "shell.execute_reply.started": "2024-06-28T13:30:13.581804Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------fold 0-----------\n",
      "epoch: 1 step: 50, loss is 0.6858367919921875\n",
      "epoch: 2 step: 15, loss is 0.628882646560669\n",
      "epoch: 2 step: 65, loss is 0.5618929862976074\n",
      "epoch: 3 step: 30, loss is 0.4210722744464874\n",
      "epoch: 3 step: 80, loss is 0.9581413865089417\n",
      "epoch: 4 step: 45, loss is 0.3028731644153595\n",
      "epoch: 5 step: 10, loss is 0.942497193813324\n",
      "epoch: 5 step: 60, loss is 0.7543084621429443\n",
      "epoch: 6 step: 25, loss is 0.30059099197387695\n",
      "epoch: 6 step: 75, loss is 0.5268030166625977\n",
      "epoch: 7 step: 40, loss is 0.3934265673160553\n",
      "epoch: 8 step: 5, loss is 0.0921880453824997\n",
      "epoch: 8 step: 55, loss is 0.48324501514434814\n",
      "epoch: 9 step: 20, loss is 0.30186137557029724\n",
      "epoch: 9 step: 70, loss is 0.7508274912834167\n",
      "epoch: 10 step: 35, loss is 0.08719252049922943\n",
      "epoch: 10 step: 85, loss is 0.7976909279823303\n",
      "epoch: 11 step: 50, loss is 0.061052706092596054\n",
      "epoch: 12 step: 15, loss is 0.33150607347488403\n",
      "epoch: 12 step: 65, loss is 0.06424576044082642\n",
      "epoch: 13 step: 30, loss is 0.2368609756231308\n",
      "epoch: 13 step: 80, loss is 0.1173725575208664\n",
      "epoch: 14 step: 45, loss is 0.05034806951880455\n",
      "epoch: 15 step: 10, loss is 0.2194080799818039\n",
      "epoch: 15 step: 60, loss is 0.18952104449272156\n",
      "epoch: 16 step: 25, loss is 0.394439697265625\n",
      "epoch: 16 step: 75, loss is 0.09355282783508301\n",
      "epoch: 17 step: 40, loss is 0.7163150310516357\n",
      "epoch: 18 step: 5, loss is 0.06461824476718903\n",
      "epoch: 18 step: 55, loss is 0.14648211002349854\n",
      "epoch: 19 step: 20, loss is 0.042688339948654175\n",
      "epoch: 19 step: 70, loss is 0.11593708395957947\n",
      "epoch: 20 step: 35, loss is 0.7175788879394531\n",
      "epoch: 20 step: 85, loss is 0.08081134408712387\n",
      "epoch: 21 step: 50, loss is 0.21896812319755554\n",
      "epoch: 22 step: 15, loss is 0.03582290932536125\n",
      "epoch: 22 step: 65, loss is 0.04802767559885979\n",
      "epoch: 23 step: 30, loss is 0.9413542151451111\n",
      "epoch: 23 step: 80, loss is 0.14229583740234375\n",
      "epoch: 24 step: 45, loss is 0.3886203169822693\n",
      "epoch: 25 step: 10, loss is 0.4507502615451813\n",
      "epoch: 25 step: 60, loss is 0.027206124737858772\n",
      "epoch: 26 step: 25, loss is 0.08247453719377518\n",
      "epoch: 26 step: 75, loss is 0.06943309307098389\n",
      "epoch: 27 step: 40, loss is 0.25737035274505615\n",
      "epoch: 28 step: 5, loss is 0.02223276160657406\n",
      "epoch: 28 step: 55, loss is 0.025464238598942757\n",
      "epoch: 29 step: 20, loss is 0.2575432062149048\n",
      "epoch: 29 step: 70, loss is 0.05141683667898178\n",
      "epoch: 30 step: 35, loss is 0.014014948159456253\n",
      "epoch: 30 step: 85, loss is 0.06355088204145432\n",
      "Accuracy on fold 0 is 0.8554\n",
      "-----------fold 1-----------\n",
      "epoch: 1 step: 50, loss is 0.6888835430145264\n",
      "epoch: 2 step: 16, loss is 0.6113322973251343\n",
      "epoch: 2 step: 66, loss is 0.5867894887924194\n",
      "epoch: 3 step: 32, loss is 0.5664619207382202\n",
      "epoch: 3 step: 82, loss is 0.46356168389320374\n",
      "epoch: 4 step: 48, loss is 0.4772810935974121\n",
      "epoch: 5 step: 14, loss is 0.34202176332473755\n",
      "epoch: 5 step: 64, loss is 0.6780030727386475\n",
      "epoch: 6 step: 30, loss is 0.1306002289056778\n",
      "epoch: 6 step: 80, loss is 0.5334435701370239\n",
      "epoch: 7 step: 46, loss is 0.4482726454734802\n",
      "epoch: 8 step: 12, loss is 0.5400292873382568\n",
      "epoch: 8 step: 62, loss is 0.36035728454589844\n",
      "epoch: 9 step: 28, loss is 0.6815780401229858\n",
      "epoch: 9 step: 78, loss is 1.135056972503662\n",
      "epoch: 10 step: 44, loss is 0.6662551164627075\n",
      "epoch: 11 step: 10, loss is 0.09004741907119751\n",
      "epoch: 11 step: 60, loss is 0.5959058403968811\n",
      "epoch: 12 step: 26, loss is 0.08576123416423798\n",
      "epoch: 12 step: 76, loss is 0.16467198729515076\n",
      "epoch: 13 step: 42, loss is 0.05061914771795273\n",
      "epoch: 14 step: 8, loss is 0.11925835907459259\n",
      "epoch: 14 step: 58, loss is 0.05679243057966232\n",
      "epoch: 15 step: 24, loss is 0.05520131066441536\n",
      "epoch: 15 step: 74, loss is 0.12944039702415466\n",
      "epoch: 16 step: 40, loss is 0.32393744587898254\n",
      "epoch: 17 step: 6, loss is 0.10131248831748962\n",
      "epoch: 17 step: 56, loss is 0.08270037174224854\n",
      "epoch: 18 step: 22, loss is 0.33014851808547974\n",
      "epoch: 18 step: 72, loss is 0.7372069954872131\n",
      "epoch: 19 step: 38, loss is 0.2666361331939697\n",
      "epoch: 20 step: 4, loss is 0.044111236929893494\n",
      "epoch: 20 step: 54, loss is 0.05242783576250076\n",
      "epoch: 21 step: 20, loss is 0.04663317650556564\n",
      "epoch: 21 step: 70, loss is 0.037663642317056656\n",
      "epoch: 22 step: 36, loss is 0.26859810948371887\n",
      "epoch: 23 step: 2, loss is 0.07938280701637268\n",
      "epoch: 23 step: 52, loss is 0.08681164681911469\n",
      "epoch: 24 step: 18, loss is 0.043261535465717316\n",
      "epoch: 24 step: 68, loss is 0.28273874521255493\n",
      "epoch: 25 step: 34, loss is 0.3413983881473541\n",
      "epoch: 25 step: 84, loss is 0.08037696033716202\n",
      "epoch: 26 step: 50, loss is 0.032695140689611435\n",
      "epoch: 27 step: 16, loss is 0.08707227557897568\n",
      "epoch: 27 step: 66, loss is 0.04253023862838745\n",
      "epoch: 28 step: 32, loss is 0.05934124439954758\n",
      "epoch: 28 step: 82, loss is 0.01017511822283268\n",
      "epoch: 29 step: 48, loss is 0.05987325683236122\n",
      "epoch: 30 step: 14, loss is 0.14884266257286072\n",
      "epoch: 30 step: 64, loss is 0.024123964831233025\n",
      "Accuracy on fold 1 is 0.8824\n",
      "-----------fold 2-----------\n",
      "epoch: 1 step: 50, loss is 0.690929651260376\n",
      "epoch: 2 step: 16, loss is 0.6437695026397705\n",
      "epoch: 2 step: 66, loss is 0.46145007014274597\n",
      "epoch: 3 step: 32, loss is 0.6537614464759827\n",
      "epoch: 3 step: 82, loss is 0.7733922600746155\n",
      "epoch: 4 step: 48, loss is 0.5079839825630188\n",
      "epoch: 5 step: 14, loss is 0.6050868630409241\n",
      "epoch: 5 step: 64, loss is 0.6172462701797485\n",
      "epoch: 6 step: 30, loss is 1.4188449382781982\n",
      "epoch: 6 step: 80, loss is 0.14047792553901672\n",
      "epoch: 7 step: 46, loss is 0.7812323570251465\n",
      "epoch: 8 step: 12, loss is 0.09340108931064606\n",
      "epoch: 8 step: 62, loss is 0.2431202083826065\n",
      "epoch: 9 step: 28, loss is 0.22148212790489197\n",
      "epoch: 9 step: 78, loss is 0.13162626326084137\n",
      "epoch: 10 step: 44, loss is 0.459795206785202\n",
      "epoch: 11 step: 10, loss is 0.3827027678489685\n",
      "epoch: 11 step: 60, loss is 0.23423965275287628\n",
      "epoch: 12 step: 26, loss is 0.08790920674800873\n",
      "epoch: 12 step: 76, loss is 0.4103839099407196\n",
      "epoch: 13 step: 42, loss is 0.12653054296970367\n",
      "epoch: 14 step: 8, loss is 0.0992877259850502\n",
      "epoch: 14 step: 58, loss is 0.3193075954914093\n",
      "epoch: 15 step: 24, loss is 0.1626090705394745\n",
      "epoch: 15 step: 74, loss is 0.12533973157405853\n",
      "epoch: 16 step: 40, loss is 0.3368200957775116\n",
      "epoch: 17 step: 6, loss is 0.7440842390060425\n",
      "epoch: 17 step: 56, loss is 0.377982497215271\n",
      "epoch: 18 step: 22, loss is 0.09348024427890778\n",
      "epoch: 18 step: 72, loss is 0.1386195868253708\n",
      "epoch: 19 step: 38, loss is 0.05662836134433746\n",
      "epoch: 20 step: 4, loss is 0.3349544107913971\n",
      "epoch: 20 step: 54, loss is 0.5807703733444214\n",
      "epoch: 21 step: 20, loss is 0.049720436334609985\n",
      "epoch: 21 step: 70, loss is 0.657909095287323\n",
      "epoch: 22 step: 36, loss is 0.2287653684616089\n",
      "epoch: 23 step: 2, loss is 0.053652480244636536\n",
      "epoch: 23 step: 52, loss is 0.3672497868537903\n",
      "epoch: 24 step: 18, loss is 0.0626874640583992\n",
      "epoch: 24 step: 68, loss is 0.3457988500595093\n",
      "epoch: 25 step: 34, loss is 0.04121502488851547\n",
      "epoch: 25 step: 84, loss is 0.041289396584033966\n",
      "epoch: 26 step: 50, loss is 0.32580679655075073\n",
      "epoch: 27 step: 16, loss is 0.03830698877573013\n",
      "epoch: 27 step: 66, loss is 0.034961093217134476\n",
      "epoch: 28 step: 32, loss is 0.6373933553695679\n",
      "epoch: 28 step: 82, loss is 0.04827822372317314\n",
      "epoch: 29 step: 48, loss is 0.012772006914019585\n",
      "epoch: 30 step: 14, loss is 0.2696744203567505\n",
      "epoch: 30 step: 64, loss is 0.04729878902435303\n",
      "Accuracy on fold 2 is 0.8837\n",
      "-----------fold 3-----------\n",
      "epoch: 1 step: 50, loss is 0.6884848475456238\n",
      "epoch: 2 step: 16, loss is 0.6311627626419067\n",
      "epoch: 2 step: 66, loss is 0.5665605068206787\n",
      "epoch: 3 step: 32, loss is 0.5795679688453674\n",
      "epoch: 3 step: 82, loss is 0.4375045895576477\n",
      "epoch: 4 step: 48, loss is 0.7607523202896118\n",
      "epoch: 5 step: 14, loss is 0.13783307373523712\n",
      "epoch: 5 step: 64, loss is 0.44534242153167725\n",
      "epoch: 6 step: 30, loss is 0.4178083539009094\n",
      "epoch: 6 step: 80, loss is 0.35538554191589355\n",
      "epoch: 7 step: 46, loss is 0.20089611411094666\n",
      "epoch: 8 step: 12, loss is 0.1679992377758026\n",
      "epoch: 8 step: 62, loss is 0.5263606309890747\n",
      "epoch: 9 step: 28, loss is 0.21466143429279327\n",
      "epoch: 9 step: 78, loss is 0.2703953683376312\n",
      "epoch: 10 step: 44, loss is 0.463800311088562\n",
      "epoch: 11 step: 10, loss is 0.15573610365390778\n",
      "epoch: 11 step: 60, loss is 0.11355738341808319\n",
      "epoch: 12 step: 26, loss is 0.5699911117553711\n",
      "epoch: 12 step: 76, loss is 0.14083611965179443\n",
      "epoch: 13 step: 42, loss is 0.06725413352251053\n",
      "epoch: 14 step: 8, loss is 0.2969987392425537\n",
      "epoch: 14 step: 58, loss is 0.3006954789161682\n",
      "epoch: 15 step: 24, loss is 0.07767020165920258\n",
      "epoch: 15 step: 74, loss is 0.4211251735687256\n",
      "epoch: 16 step: 40, loss is 0.10487861931324005\n",
      "epoch: 17 step: 6, loss is 0.03654813393950462\n",
      "epoch: 17 step: 56, loss is 0.07513339817523956\n",
      "epoch: 18 step: 22, loss is 0.037330251187086105\n",
      "epoch: 18 step: 72, loss is 0.5775625109672546\n",
      "epoch: 19 step: 38, loss is 0.058104559779167175\n",
      "epoch: 20 step: 4, loss is 0.7402918338775635\n",
      "epoch: 20 step: 54, loss is 0.09633421897888184\n",
      "epoch: 21 step: 20, loss is 0.18247544765472412\n",
      "epoch: 21 step: 70, loss is 0.042331770062446594\n",
      "epoch: 22 step: 36, loss is 0.4662627577781677\n",
      "epoch: 23 step: 2, loss is 0.40660595893859863\n",
      "epoch: 23 step: 52, loss is 0.12916013598442078\n",
      "epoch: 24 step: 18, loss is 0.13273663818836212\n",
      "epoch: 24 step: 68, loss is 0.018650054931640625\n",
      "epoch: 25 step: 34, loss is 0.0901932492852211\n",
      "epoch: 25 step: 84, loss is 0.029144035652279854\n",
      "epoch: 26 step: 50, loss is 0.05586323142051697\n",
      "epoch: 27 step: 16, loss is 0.04335429519414902\n",
      "epoch: 27 step: 66, loss is 0.11947648227214813\n",
      "epoch: 28 step: 32, loss is 0.12884600460529327\n",
      "epoch: 28 step: 82, loss is 0.037471164017915726\n",
      "epoch: 29 step: 48, loss is 0.06135547161102295\n",
      "epoch: 30 step: 14, loss is 0.1869063824415207\n",
      "epoch: 30 step: 64, loss is 0.20415101945400238\n",
      "Accuracy on fold 3 is 0.8929\n",
      "-----------fold 4-----------\n",
      "epoch: 1 step: 50, loss is 0.6871609687805176\n",
      "epoch: 2 step: 16, loss is 0.6653270721435547\n",
      "epoch: 2 step: 66, loss is 0.6521074175834656\n",
      "epoch: 3 step: 32, loss is 0.34290945529937744\n",
      "epoch: 3 step: 82, loss is 0.4175589084625244\n",
      "epoch: 4 step: 48, loss is 0.14140908420085907\n",
      "epoch: 5 step: 14, loss is 0.3029084801673889\n",
      "epoch: 5 step: 64, loss is 1.071256399154663\n",
      "epoch: 6 step: 30, loss is 0.670452892780304\n",
      "epoch: 6 step: 80, loss is 0.14161810278892517\n",
      "epoch: 7 step: 46, loss is 0.3477246165275574\n",
      "epoch: 8 step: 12, loss is 0.24527916312217712\n",
      "epoch: 8 step: 62, loss is 0.18116642534732819\n",
      "epoch: 9 step: 28, loss is 0.4449574947357178\n",
      "epoch: 9 step: 78, loss is 0.6327319741249084\n",
      "epoch: 10 step: 44, loss is 0.5198723077774048\n",
      "epoch: 11 step: 10, loss is 0.13016104698181152\n",
      "epoch: 11 step: 60, loss is 0.6279429793357849\n",
      "epoch: 12 step: 26, loss is 0.41453030705451965\n",
      "epoch: 12 step: 76, loss is 0.281053364276886\n",
      "epoch: 13 step: 42, loss is 0.6303849816322327\n",
      "epoch: 14 step: 8, loss is 0.1073429137468338\n",
      "epoch: 14 step: 58, loss is 0.06931467354297638\n",
      "epoch: 15 step: 24, loss is 0.08970437943935394\n",
      "epoch: 15 step: 74, loss is 0.620494544506073\n",
      "epoch: 16 step: 40, loss is 0.060528695583343506\n",
      "epoch: 17 step: 6, loss is 0.12073176354169846\n",
      "epoch: 17 step: 56, loss is 0.11735890060663223\n",
      "epoch: 18 step: 22, loss is 0.2022869884967804\n",
      "epoch: 18 step: 72, loss is 0.2386234849691391\n",
      "epoch: 19 step: 38, loss is 0.05020851641893387\n",
      "epoch: 20 step: 4, loss is 0.26376962661743164\n",
      "epoch: 20 step: 54, loss is 0.10838623344898224\n",
      "epoch: 21 step: 20, loss is 0.06862686574459076\n",
      "epoch: 21 step: 70, loss is 0.5866990089416504\n",
      "epoch: 22 step: 36, loss is 0.12603962421417236\n",
      "epoch: 23 step: 2, loss is 0.09994757920503616\n",
      "epoch: 23 step: 52, loss is 0.4374350309371948\n",
      "epoch: 24 step: 18, loss is 0.04627513140439987\n",
      "epoch: 24 step: 68, loss is 0.3683004677295685\n",
      "epoch: 25 step: 34, loss is 0.27319368720054626\n",
      "epoch: 25 step: 84, loss is 0.01821925863623619\n",
      "epoch: 26 step: 50, loss is 0.054212771356105804\n",
      "epoch: 27 step: 16, loss is 0.1780339479446411\n",
      "epoch: 27 step: 66, loss is 0.044341713190078735\n",
      "epoch: 28 step: 32, loss is 0.03700889274477959\n",
      "epoch: 28 step: 82, loss is 0.02394159510731697\n",
      "epoch: 29 step: 48, loss is 0.06567808985710144\n",
      "epoch: 30 step: 14, loss is 0.2236291915178299\n",
      "epoch: 30 step: 64, loss is 0.01288408413529396\n",
      "Accuracy on fold 4 is 0.8941\n",
      "Average accuracy on t1 is 0.8817\n"
     ]
    }
   ],
   "source": [
    "acc=[]\n",
    "for i in range(5):\n",
    "    print(f\"-----------fold {i}-----------\")\n",
    "    cfg=Config()\n",
    "    model=MLP(para['gene_emb'].value(),cfg)\n",
    "    optimizer=nn.Adam(model.trainable_params(),1e-4,weight_decay=1e-5)\n",
    "    wrapper=Wrapper(model,optimizer)\n",
    "    trainer=Model(\n",
    "        wrapper,\n",
    "        amp_level='O0',\n",
    "        eval_network=model,\n",
    "        metrics={\n",
    "            'accuracy':annote_metric(2,key='accuracy'),\n",
    "        },\n",
    "        eval_indexes=[0,1,2]\n",
    "    )\n",
    "    scrna=SCrna('../datasets/processed/','t1',fold=i,mode='train')\n",
    "    trainset=build_dataset(\n",
    "        scrna,4,\n",
    "        drop=True\n",
    "    )\n",
    "    sctest=SCrna('../datasets/processed/','t1',fold=i,mode='test')\n",
    "    testset=build_dataset(\n",
    "        sctest,\n",
    "        len(sctest),\n",
    "        drop=False\n",
    "    )\n",
    "    loss_cb = LossMonitor(50)\n",
    "    cbs=[loss_cb]\n",
    "    trainer.train(30,trainset,callbacks=cbs)\n",
    "    acci=trainer.eval(testset)['accuracy']\n",
    "    print(f'Accuracy on fold {i} is {acci:.4f}')\n",
    "    acc.append(acci)\n",
    "print(f\"Average accuracy on t1 is {sum(acc)/5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e796913-e101-471c-ae3c-2a75a4d2b43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ms22]",
   "language": "python",
   "name": "conda-env-ms22-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
