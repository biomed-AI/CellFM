{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c55d705",
   "metadata": {},
   "source": [
    "# CellFM Fine-tune for Cell Annotation Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1da129-51bb-40f0-9cf0-141ccef906e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:08:32.667840Z",
     "iopub.status.busy": "2024-06-26T12:08:32.667174Z",
     "iopub.status.idle": "2024-06-26T12:09:08.201757Z",
     "shell.execute_reply": "2024-06-26T12:09:08.200759Z",
     "shell.execute_reply.started": "2024-06-26T12:08:32.667786Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] ME(1838828:140063136855872,MainProcess):2024-12-12-20:14:47.607.46 [mindspore/run_check/_check_version.py:230] Cuda ['10.1', '11.1', '11.6'] version(libcudart*.so need by mindspore-gpu) is not found. Please confirm that the path of cuda is set to the env LD_LIBRARY_PATH, or check whether the CUDA version in wheel package and the CUDA runtime in current device matches. Please refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[ERROR] ME(1838828:140063136855872,MainProcess):2024-12-12-20:14:47.137.474 [mindspore/run_check/_check_version.py:230] Cuda ['10.1', '11.1', '11.6'] version(libcudnn*.so need by mindspore-gpu) is not found. Please confirm that the path of cuda is set to the env LD_LIBRARY_PATH, or check whether the CUDA version in wheel package and the CUDA runtime in current device matches. Please refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(1838828:140063136855872,MainProcess):2024-12-12-20:14:47.139.771 [mindspore/run_check/_check_version.py:98] Can not found cuda libs. Please confirm that the correct cuda version has been installed. Refer to the installation guidelines: https://www.mindspore.cn/install\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import mindspore as ms\n",
    "import mindspore.numpy as mnp\n",
    "import mindspore.scipy as msc\n",
    "import mindspore.dataset as ds\n",
    "from tqdm import tqdm,trange\n",
    "from mindspore import nn,ops\n",
    "from scipy.sparse import csr_matrix as csm\n",
    "from mindspore.ops import operations as P\n",
    "from mindspore.amp import FixedLossScaleManager,all_finite,DynamicLossScaleManager\n",
    "from mindspore.train import Model, CheckpointConfig, ModelCheckpoint, LossMonitor\n",
    "from mindspore.context import ParallelMode\n",
    "from mindspore.communication import init, get_rank, get_group_size\n",
    "from mindspore.parallel._utils import _get_parallel_mode\n",
    "from mindspore.common.initializer import initializer, XavierNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "340697f0-f9fa-4126-a66a-edffdaf7f859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:09:08.203652Z",
     "iopub.status.busy": "2024-06-26T12:09:08.203184Z",
     "iopub.status.idle": "2024-06-26T12:09:08.207207Z",
     "shell.execute_reply": "2024-06-26T12:09:08.206693Z",
     "shell.execute_reply.started": "2024-06-26T12:09:08.203628Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5737d88d-dce4-4149-8217-3b8a8bc77324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:09:08.208344Z",
     "iopub.status.busy": "2024-06-26T12:09:08.207940Z",
     "iopub.status.idle": "2024-06-26T12:09:08.645116Z",
     "shell.execute_reply": "2024-06-26T12:09:08.644250Z",
     "shell.execute_reply.started": "2024-06-26T12:09:08.208325Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from config import Config\n",
    "from annotation_model import *\n",
    "from metrics import annote_metric\n",
    "from utils import Wrapper\n",
    "from data_process import Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992731c8",
   "metadata": {},
   "source": [
    "## Prepare training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20d430d-1f4d-4b18-b386-612f5b381534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:09:08.647024Z",
     "iopub.status.busy": "2024-06-26T12:09:08.646800Z",
     "iopub.status.idle": "2024-06-26T12:09:08.651621Z",
     "shell.execute_reply": "2024-06-26T12:09:08.650890Z",
     "shell.execute_reply.started": "2024-06-26T12:09:08.647004Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If using the LoRA strategy, non-LoRA layers in the backbone will be frozen here.\n",
    "def freeze_module(module,filter_tag=[None]):\n",
    "    for param in module.trainable_params():\n",
    "        x=False\n",
    "        for tag in filter_tag:\n",
    "            if tag and tag in param.name:\n",
    "                x=True\n",
    "                break\n",
    "        param.requires_grad = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e787f5d5-db9f-4473-a3cf-3ec159a31b3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:09:08.652490Z",
     "iopub.status.busy": "2024-06-26T12:09:08.652296Z",
     "iopub.status.idle": "2024-06-26T12:09:08.661007Z",
     "shell.execute_reply": "2024-06-26T12:09:08.660286Z",
     "shell.execute_reply.started": "2024-06-26T12:09:08.652473Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading training and testing datasets in H5AD format.\n",
    "def read_h5ad(path):\n",
    "    train_data = sc.read_h5ad(path+\"/train.h5ad\")\n",
    "    test_data = sc.read_h5ad(path+\"/test.h5ad\")\n",
    "\n",
    "    train_data.obs['train'] = 0\n",
    "    test_data.obs['train']  = 2\n",
    "\n",
    "    adata = ad.concat([train_data, test_data], join='outer')\n",
    "    print('origin shape:',adata.shape,len(adata.obs['cell_type'].unique()))\n",
    "        \n",
    "    data=adata.X.astype(np.float32)\n",
    "    T=adata.X.sum(1)\n",
    "    data=csm(np.round(data/np.maximum(1,T/1e5,dtype=np.float32)))\n",
    "    data.eliminate_zeros()\n",
    "    adata.X=data\n",
    "    \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c542bfb-5919-4a28-926f-07e72bb53448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:09:08.661906Z",
     "iopub.status.busy": "2024-06-26T12:09:08.661714Z",
     "iopub.status.idle": "2024-06-26T12:09:08.680291Z",
     "shell.execute_reply": "2024-06-26T12:09:08.679394Z",
     "shell.execute_reply.started": "2024-06-26T12:09:08.661889Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SCrna():\n",
    "    def __init__(self,adata,mode='train',prep=True):\n",
    "        self.cls=len(adata.obs['cell_type'].unique())\n",
    "        if mode==\"train\":\n",
    "            adata=adata[adata.obs.train==0]\n",
    "        elif mode=='val':\n",
    "            adata=adata[adata.obs.train==1]\n",
    "        else:\n",
    "            adata=adata[adata.obs.train==2]\n",
    "        self.gene_info=pd.read_csv(f'../../csv/expand_gene_info.csv',index_col=0,header=0)\n",
    "        self.geneset={j:i+1 for i,j in enumerate(self.gene_info.index)}\n",
    "        \n",
    "        gene=np.intersect1d(adata.var_names,self.gene_info.index)\n",
    "        adata=adata[:,gene].copy()\n",
    "        adata.obs['cell_type']=adata.obs['cell_type'].astype('category')\n",
    "        label=adata.obs['cell_type'].cat.codes.values\n",
    "        adata.obs['label']=label\n",
    "        if prep:\n",
    "            adata.layers['x_normed']=sc.pp.normalize_total(adata,target_sum=1e4,inplace=False)['X']\n",
    "            adata.layers['x_log1p']=adata.layers['x_normed']\n",
    "            sc.pp.log1p(adata,layer='x_log1p')\n",
    "        self.adata=adata\n",
    "        self.id2label=adata.obs['cell_type'].cat.categories.values\n",
    "        self.gene=np.array([self.geneset[i] for i in self.adata.var_names]).astype(np.int32)\n",
    "        self.cls=len(adata.obs['cell_type'].unique())\n",
    "        self.label=self.adata.obs['label'].values.astype(np.int32)\n",
    "        print(f'{mode} adata:',adata.shape,self.cls)\n",
    "        if prep:\n",
    "            self.data=self.adata.layers['x_log1p'].A.astype(np.float32)\n",
    "        else:\n",
    "            self.data=self.adata.X.astype(np.int32)\n",
    "    def __len__(self):\n",
    "        return len(self.adata)\n",
    "    def __getitem__(self,idx):\n",
    "        data=self.data[idx].reshape(-1)\n",
    "        label=self.label[idx]\n",
    "        return data,self.gene,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70766405-a73f-46ba-a918-e3d88f2c9eda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:09:08.681848Z",
     "iopub.status.busy": "2024-06-26T12:09:08.681404Z",
     "iopub.status.idle": "2024-06-26T12:09:08.692598Z",
     "shell.execute_reply": "2024-06-26T12:09:08.691704Z",
     "shell.execute_reply.started": "2024-06-26T12:09:08.681819Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a data loader.\n",
    "def build_dataset(\n",
    "    data,prep,batch,\n",
    "    rank_size=None,\n",
    "    rank_id=None,\n",
    "    drop=True,\n",
    "    shuffle=True\n",
    "):\n",
    "    dataset = ds.GeneratorDataset(\n",
    "        data, \n",
    "        column_names=['data','gene','label'],\n",
    "        shuffle=shuffle,\n",
    "        num_shards=rank_size, \n",
    "        shard_id=rank_id\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        prep.seperate, input_columns=['data'],\n",
    "        output_columns=['data', 'nonz','zero']\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        prep.sample, input_columns=['data','nonz','zero'],\n",
    "        output_columns=['data','nonz','cuted','z_sample','seq_len']\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        prep.compress, input_columns=['data','nonz'],\n",
    "        output_columns=['data','nonz_data', 'nonz']\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        prep.compress, input_columns=['gene','nonz'],\n",
    "        output_columns=['gene','nonz_gene', 'nonz']\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        prep.attn_mask, input_columns=['seq_len'],\n",
    "        output_columns=['zero_idx']\n",
    "    )\n",
    "    dataset = dataset.map(prep.pad_zero, input_columns=['nonz_data'])\n",
    "    dataset = dataset.map(prep.pad_zero, input_columns=['nonz_gene'])\n",
    "    dataset=dataset.project(\n",
    "        columns=['nonz_data','nonz_gene','zero_idx','label']\n",
    "    )\n",
    "    dataset = dataset.batch(\n",
    "        batch,\n",
    "        num_parallel_workers=4, \n",
    "        drop_remainder=drop, \n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7d22789-889c-4db4-b828-63bdb94afbdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:09:08.694008Z",
     "iopub.status.busy": "2024-06-26T12:09:08.693682Z",
     "iopub.status.idle": "2024-06-26T12:09:08.698960Z",
     "shell.execute_reply": "2024-06-26T12:09:08.698089Z",
     "shell.execute_reply.started": "2024-06-26T12:09:08.693981Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here, you can choose the type and number of the GPU, such as Ascend and GPU.\n",
    "ms.set_context(\n",
    "    device_target='GPU', \n",
    "    mode=ms.GRAPH_MODE,\n",
    "    device_id=0,\n",
    ")\n",
    "ms.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa54c88-b012-47a9-a17e-05efbcabb8c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:09:08.700779Z",
     "iopub.status.busy": "2024-06-26T12:09:08.700033Z",
     "iopub.status.idle": "2024-06-26T12:09:17.485125Z",
     "shell.execute_reply": "2024-06-26T12:09:17.484216Z",
     "shell.execute_reply.started": "2024-06-26T12:09:08.700750Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin shape: (4014, 20007) 12\n",
      "train adata: (3402, 15760) 12\n",
      "test adata: (612, 15760) 12\n"
     ]
    }
   ],
   "source": [
    "adata=read_h5ad(f\"../../datasets/cell_annotion/Inter/Liver3\")\n",
    "trainset=SCrna(adata,mode='train')\n",
    "testset=SCrna(adata,mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec6eb299-0726-4004-a064-a0f1ad264bfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:09:17.487085Z",
     "iopub.status.busy": "2024-06-26T12:09:17.486898Z",
     "iopub.status.idle": "2024-06-26T12:09:17.490907Z",
     "shell.execute_reply": "2024-06-26T12:09:17.490091Z",
     "shell.execute_reply.started": "2024-06-26T12:09:17.487067Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg=Config()\n",
    "cfg.num_cls=trainset.cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e0e09b3-474f-4c24-a64e-2945b91afeb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:09:17.491635Z",
     "iopub.status.busy": "2024-06-26T12:09:17.491475Z",
     "iopub.status.idle": "2024-06-26T12:09:17.501577Z",
     "shell.execute_reply": "2024-06-26T12:09:17.500873Z",
     "shell.execute_reply.started": "2024-06-26T12:09:17.491621Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prep=Prepare(\n",
    "    cfg.nonz_len,pad=1,mask_ratio=0,random=False\n",
    ")\n",
    "train_loader=build_dataset(\n",
    "    trainset,\n",
    "    prep,\n",
    "    16,\n",
    "    drop=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_loader=build_dataset(\n",
    "    testset,\n",
    "    prep,\n",
    "    1,\n",
    "    drop=False,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95435ab",
   "metadata": {},
   "source": [
    "## Create the training model for CellFM.\n",
    "Here, you can choose to use the LoRA strategy to accelerate model training.\n",
    "If you want to use the LoRA strategy, please set the LoRA parameter to 32 or 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "392160b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.lora=0 # 32,64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377701df-4390-49d3-8b57-c1f838cff281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:09:17.502287Z",
     "iopub.status.busy": "2024-06-26T12:09:17.502132Z",
     "iopub.status.idle": "2024-06-26T12:09:46.211822Z",
     "shell.execute_reply": "2024-06-26T12:09:46.210586Z",
     "shell.execute_reply.started": "2024-06-26T12:09:17.502274Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "para=ms.load_checkpoint(\"../../checkpoint/CellFM_80M_weight.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76df8be4-2701-4915-9d01-5ff091ac885f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:09:46.213415Z",
     "iopub.status.busy": "2024-06-26T12:09:46.213146Z",
     "iopub.status.idle": "2024-06-26T12:10:03.557228Z",
     "shell.execute_reply": "2024-06-26T12:10:03.555859Z",
     "shell.execute_reply.started": "2024-06-26T12:09:46.213387Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "backbone=Backbone(len(trainset.geneset),cfg)\n",
    "ms.load_param_into_net(backbone, para)\n",
    "model=Net(backbone,cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dafce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.lora>0:\n",
    "    freeze_module(model.extractor,[\"lora\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b3b63d7-46a4-45ea-9307-823e71e545ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:10:03.570857Z",
     "iopub.status.busy": "2024-06-26T12:10:03.570229Z",
     "iopub.status.idle": "2024-06-26T12:10:04.039259Z",
     "shell.execute_reply": "2024-06-26T12:10:04.038205Z",
     "shell.execute_reply.started": "2024-06-26T12:10:03.570830Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer=nn.Adam(model.trainable_params(),1e-4,weight_decay=1e-5)\n",
    "update_cell=nn.DynamicLossScaleUpdateCell(1,2,1000)\n",
    "wrapper=Wrapper(model,optimizer)\n",
    "trainer=Model(\n",
    "    wrapper,\n",
    "    eval_network=model,\n",
    "    amp_level='O0',\n",
    "    metrics={\n",
    "        'accuracy':annote_metric(trainset.cls,key='accuracy'),\n",
    "    },\n",
    "    eval_indexes=[0,1,2]\n",
    ")\n",
    "loss_cb = LossMonitor(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9cceaea-0044-4f11-9249-9766746294c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:10:51.761637Z",
     "iopub.status.busy": "2024-06-26T12:10:51.761078Z",
     "iopub.status.idle": "2024-06-26T12:10:51.767692Z",
     "shell.execute_reply": "2024-06-26T12:10:51.766676Z",
     "shell.execute_reply.started": "2024-06-26T12:10:51.761612Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_cb = LossMonitor(20)\n",
    "ckpt_config = CheckpointConfig(\n",
    "    save_checkpoint_steps=len(train_loader),\n",
    "    keep_checkpoint_max=1,\n",
    "    integrated_save=False,\n",
    "    async_save=False\n",
    ")\n",
    "ckpt_cb = ModelCheckpoint(\n",
    "    prefix=f'Liver3_inter', \n",
    "    directory=f\"../../checkpoint/CellAnnotation/\", \n",
    "    config=ckpt_config\n",
    ")\n",
    "cbs=[loss_cb,ckpt_cb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4704cf69",
   "metadata": {},
   "source": [
    "## Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afdc6c97-c541-4210-8688-672bafe5b058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T01:32:55.178632Z",
     "iopub.status.busy": "2024-06-26T01:32:55.178474Z",
     "iopub.status.idle": "2024-06-26T11:57:00.626089Z",
     "shell.execute_reply": "2024-06-26T11:57:00.617142Z",
     "shell.execute_reply.started": "2024-06-26T01:32:55.178619Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 20, loss is 4.0819597244262695\n",
      "epoch: 1 step: 40, loss is 3.0292000770568848\n",
      "epoch: 1 step: 60, loss is 0.8533070683479309\n",
      "epoch: 1 step: 80, loss is 0.2698594331741333\n",
      "epoch: 1 step: 100, loss is 0.7719871997833252\n",
      "epoch: 1 step: 120, loss is 0.3602368235588074\n",
      "epoch: 1 step: 140, loss is 0.07322302460670471\n",
      "epoch: 1 step: 160, loss is 0.4552229046821594\n",
      "epoch: 1 step: 180, loss is 0.36717361211776733\n",
      "epoch: 1 step: 200, loss is 0.47287940979003906\n",
      "epoch: 2 step: 8, loss is 0.028203625231981277\n",
      "epoch: 2 step: 28, loss is 0.027636883780360222\n",
      "epoch: 2 step: 48, loss is 0.02927451767027378\n",
      "epoch: 2 step: 68, loss is 0.17948482930660248\n",
      "epoch: 2 step: 88, loss is 0.011553077958524227\n",
      "epoch: 2 step: 108, loss is 0.03228188306093216\n",
      "epoch: 2 step: 128, loss is 1.0221357345581055\n",
      "epoch: 2 step: 148, loss is 0.24751926958560944\n",
      "epoch: 2 step: 168, loss is 0.26803597807884216\n",
      "epoch: 2 step: 188, loss is 0.07014358788728714\n",
      "epoch: 2 step: 208, loss is 0.22989217936992645\n",
      "epoch: 3 step: 16, loss is 0.03698323667049408\n",
      "epoch: 3 step: 36, loss is 0.002865548012778163\n",
      "epoch: 3 step: 56, loss is 0.007642755750566721\n",
      "epoch: 3 step: 76, loss is 0.002926172222942114\n",
      "epoch: 3 step: 96, loss is 0.04991403967142105\n",
      "epoch: 3 step: 116, loss is 0.004057059995830059\n",
      "epoch: 3 step: 136, loss is 0.002378819277510047\n",
      "epoch: 3 step: 156, loss is 0.0009079404408112168\n",
      "epoch: 3 step: 176, loss is 0.0019572852179408073\n",
      "epoch: 3 step: 196, loss is 0.004058338701725006\n",
      "epoch: 4 step: 4, loss is 0.021251408383250237\n",
      "epoch: 4 step: 24, loss is 0.00048409512965008616\n",
      "epoch: 4 step: 44, loss is 0.39938104152679443\n",
      "epoch: 4 step: 64, loss is 0.0005379110225476325\n",
      "epoch: 4 step: 84, loss is 0.009858649224042892\n",
      "epoch: 4 step: 104, loss is 0.00048652157420292497\n",
      "epoch: 4 step: 124, loss is 0.08487678319215775\n",
      "epoch: 4 step: 144, loss is 0.00914422981441021\n",
      "epoch: 4 step: 164, loss is 0.0022466671653091908\n",
      "epoch: 4 step: 184, loss is 0.0008894724887795746\n",
      "epoch: 4 step: 204, loss is 0.0015338602242991328\n",
      "epoch: 5 step: 12, loss is 0.00047838129103183746\n",
      "epoch: 5 step: 32, loss is 0.06737477332353592\n",
      "epoch: 5 step: 52, loss is 0.0002866975264623761\n",
      "epoch: 5 step: 72, loss is 0.0004480495408643037\n",
      "epoch: 5 step: 92, loss is 0.00023115353542380035\n",
      "epoch: 5 step: 112, loss is 0.0003534320567268878\n",
      "epoch: 5 step: 132, loss is 0.0001773407420841977\n",
      "epoch: 5 step: 152, loss is 0.0004093809984624386\n",
      "epoch: 5 step: 172, loss is 0.0003505463246256113\n",
      "epoch: 5 step: 192, loss is 0.0004949494614265859\n",
      "epoch: 5 step: 212, loss is 0.0001688541378825903\n",
      "epoch: 6 step: 20, loss is 0.00020277959993109107\n",
      "epoch: 6 step: 40, loss is 0.0002913491043727845\n",
      "epoch: 6 step: 60, loss is 0.0002183704636991024\n",
      "epoch: 6 step: 80, loss is 0.0007213084027171135\n",
      "epoch: 6 step: 100, loss is 0.00014045304851606488\n",
      "epoch: 6 step: 120, loss is 0.0003307690203655511\n",
      "epoch: 6 step: 140, loss is 0.00013190138270147145\n",
      "epoch: 6 step: 160, loss is 0.0002490882179699838\n",
      "epoch: 6 step: 180, loss is 0.00014338220353238285\n",
      "epoch: 6 step: 200, loss is 0.00046581600327044725\n",
      "epoch: 7 step: 8, loss is 0.0032660875003784895\n",
      "epoch: 7 step: 28, loss is 0.005584266036748886\n",
      "epoch: 7 step: 48, loss is 0.0003256272175349295\n",
      "epoch: 7 step: 68, loss is 0.03806536644697189\n",
      "epoch: 7 step: 88, loss is 0.001348041114397347\n",
      "epoch: 7 step: 108, loss is 0.0004921343643218279\n",
      "epoch: 7 step: 128, loss is 0.00030623949714936316\n",
      "epoch: 7 step: 148, loss is 0.03860950097441673\n",
      "epoch: 7 step: 168, loss is 0.0006887695053592324\n",
      "epoch: 7 step: 188, loss is 0.00012070289085386321\n",
      "epoch: 7 step: 208, loss is 0.0007050696294754744\n",
      "epoch: 8 step: 16, loss is 0.00025691912742331624\n",
      "epoch: 8 step: 36, loss is 4.640758197638206e-05\n",
      "epoch: 8 step: 56, loss is 0.0026627997867763042\n",
      "epoch: 8 step: 76, loss is 0.0009357067756354809\n",
      "epoch: 8 step: 96, loss is 0.0012576769804582\n",
      "epoch: 8 step: 116, loss is 9.630227577872574e-05\n",
      "epoch: 8 step: 136, loss is 0.0001921251241583377\n",
      "epoch: 8 step: 156, loss is 0.00041638908442109823\n",
      "epoch: 8 step: 176, loss is 0.014424954541027546\n",
      "epoch: 8 step: 196, loss is 0.00021191625273786485\n",
      "epoch: 9 step: 4, loss is 0.0001339475711574778\n",
      "epoch: 9 step: 24, loss is 5.668813901138492e-05\n",
      "epoch: 9 step: 44, loss is 8.013175101950765e-05\n",
      "epoch: 9 step: 64, loss is 0.00015485213953070343\n",
      "epoch: 9 step: 84, loss is 9.859959391178563e-05\n",
      "epoch: 9 step: 104, loss is 8.809363498585299e-05\n",
      "epoch: 9 step: 124, loss is 0.00023295255959965289\n",
      "epoch: 9 step: 144, loss is 0.00013232548371888697\n",
      "epoch: 9 step: 164, loss is 0.00017419019422959536\n",
      "epoch: 9 step: 184, loss is 0.00010640594700817019\n",
      "epoch: 9 step: 204, loss is 0.0003600193012971431\n",
      "epoch: 10 step: 12, loss is 0.00018741408712230623\n",
      "epoch: 10 step: 32, loss is 0.00010681447747629136\n",
      "epoch: 10 step: 52, loss is 5.32888516318053e-05\n",
      "epoch: 10 step: 72, loss is 9.510694508207962e-05\n",
      "epoch: 10 step: 92, loss is 0.00017409435531590134\n",
      "epoch: 10 step: 112, loss is 0.0004056534089613706\n",
      "epoch: 10 step: 132, loss is 0.00015638313197996467\n",
      "epoch: 10 step: 152, loss is 5.573560338234529e-05\n",
      "epoch: 10 step: 172, loss is 0.00018046298646368086\n",
      "epoch: 10 step: 192, loss is 4.828372038900852e-05\n",
      "epoch: 10 step: 212, loss is 2.875131758628413e-05\n",
      "epoch: 11 step: 20, loss is 0.0001130535383708775\n",
      "epoch: 11 step: 40, loss is 3.066596400458366e-05\n",
      "epoch: 11 step: 60, loss is 2.633002986840438e-05\n",
      "epoch: 11 step: 80, loss is 0.00023055948258843273\n",
      "epoch: 11 step: 100, loss is 5.25469149579294e-05\n",
      "epoch: 11 step: 120, loss is 0.00010310632933396846\n",
      "epoch: 11 step: 140, loss is 7.768983778078109e-05\n",
      "epoch: 11 step: 160, loss is 8.48385680001229e-05\n",
      "epoch: 11 step: 180, loss is 4.080551298102364e-05\n",
      "epoch: 11 step: 200, loss is 4.385279316920787e-05\n",
      "epoch: 12 step: 8, loss is 0.0001582086260896176\n",
      "epoch: 12 step: 28, loss is 0.00012103879998903722\n",
      "epoch: 12 step: 48, loss is 3.812338036368601e-05\n",
      "epoch: 12 step: 68, loss is 0.00010611476318445057\n",
      "epoch: 12 step: 88, loss is 4.7436580643989146e-05\n",
      "epoch: 12 step: 108, loss is 5.546452302951366e-05\n",
      "epoch: 12 step: 128, loss is 4.728618296212517e-05\n",
      "epoch: 12 step: 148, loss is 0.00012283274554647505\n",
      "epoch: 12 step: 168, loss is 4.68748330604285e-05\n",
      "epoch: 12 step: 188, loss is 2.2433354388340376e-05\n",
      "epoch: 12 step: 208, loss is 1.3522716471925378e-05\n",
      "epoch: 13 step: 16, loss is 1.8715683836489916e-05\n",
      "epoch: 13 step: 36, loss is 4.8010359023464844e-05\n",
      "epoch: 13 step: 56, loss is 4.472924047149718e-05\n",
      "epoch: 13 step: 76, loss is 4.1036386392079294e-05\n",
      "epoch: 13 step: 96, loss is 2.392341230006423e-05\n",
      "epoch: 13 step: 116, loss is 1.9773659005295485e-05\n",
      "epoch: 13 step: 136, loss is 6.547183147631586e-05\n",
      "epoch: 13 step: 156, loss is 4.457442628336139e-05\n",
      "epoch: 13 step: 176, loss is 0.00013425889483187348\n",
      "epoch: 13 step: 196, loss is 3.293058762210421e-05\n",
      "epoch: 14 step: 4, loss is 5.449130912893452e-05\n",
      "epoch: 14 step: 24, loss is 1.747110582073219e-05\n",
      "epoch: 14 step: 44, loss is 2.8467693482525647e-05\n",
      "epoch: 14 step: 64, loss is 5.74742880417034e-05\n",
      "epoch: 14 step: 84, loss is 3.249835208407603e-05\n",
      "epoch: 14 step: 104, loss is 2.7864407456945628e-05\n",
      "epoch: 14 step: 124, loss is 1.1972985703323502e-05\n",
      "epoch: 14 step: 144, loss is 0.015285213477909565\n",
      "epoch: 14 step: 164, loss is 0.48106762766838074\n",
      "epoch: 14 step: 184, loss is 0.11868157237768173\n",
      "epoch: 14 step: 204, loss is 0.0033290863502770662\n",
      "epoch: 15 step: 12, loss is 0.03428458049893379\n",
      "epoch: 15 step: 32, loss is 0.007213437929749489\n",
      "epoch: 15 step: 52, loss is 0.03708361089229584\n",
      "epoch: 15 step: 72, loss is 0.050831396132707596\n",
      "epoch: 15 step: 92, loss is 0.016312530264258385\n",
      "epoch: 15 step: 112, loss is 0.0010768122738227248\n",
      "epoch: 15 step: 132, loss is 0.06442891061306\n",
      "epoch: 15 step: 152, loss is 0.0975981056690216\n",
      "epoch: 15 step: 172, loss is 0.06755443662405014\n",
      "epoch: 15 step: 192, loss is 0.003077324479818344\n",
      "epoch: 15 step: 212, loss is 0.2020033597946167\n",
      "epoch: 16 step: 20, loss is 0.0026057157665491104\n",
      "epoch: 16 step: 40, loss is 0.0017996986862272024\n",
      "epoch: 16 step: 60, loss is 0.003198648802936077\n",
      "epoch: 16 step: 80, loss is 0.20365168154239655\n",
      "epoch: 16 step: 100, loss is 0.00013944348029326648\n",
      "epoch: 16 step: 120, loss is 0.0004394075949676335\n",
      "epoch: 16 step: 140, loss is 0.0001116164421546273\n",
      "epoch: 16 step: 160, loss is 0.9370954036712646\n",
      "epoch: 16 step: 180, loss is 0.001235375995747745\n",
      "epoch: 16 step: 200, loss is 0.07720821350812912\n",
      "epoch: 17 step: 8, loss is 0.00010566967830527574\n",
      "epoch: 17 step: 28, loss is 0.005691478028893471\n",
      "epoch: 17 step: 48, loss is 0.003078761510550976\n",
      "epoch: 17 step: 68, loss is 0.0015599330654367805\n",
      "epoch: 17 step: 88, loss is 0.00012687919661402702\n",
      "epoch: 17 step: 108, loss is 0.00020761004998348653\n",
      "epoch: 17 step: 128, loss is 8.668498776387423e-05\n",
      "epoch: 17 step: 148, loss is 0.00011044845450669527\n",
      "epoch: 17 step: 168, loss is 0.0006125283543951809\n",
      "epoch: 17 step: 188, loss is 0.0007398995803669095\n",
      "epoch: 17 step: 208, loss is 5.3366391512099653e-05\n",
      "epoch: 18 step: 16, loss is 0.00013395026326179504\n",
      "epoch: 18 step: 36, loss is 5.2968352974858135e-05\n",
      "epoch: 18 step: 56, loss is 0.00024411034246440977\n",
      "epoch: 18 step: 76, loss is 5.199395673116669e-05\n",
      "epoch: 18 step: 96, loss is 0.00018008853658102453\n",
      "epoch: 18 step: 116, loss is 2.545809547882527e-05\n",
      "epoch: 18 step: 136, loss is 4.6560038754250854e-05\n",
      "epoch: 18 step: 156, loss is 0.000163431788678281\n",
      "epoch: 18 step: 176, loss is 6.0357800975907594e-05\n",
      "epoch: 18 step: 196, loss is 0.00014316986198537052\n",
      "epoch: 19 step: 4, loss is 2.8587295673787594e-05\n",
      "epoch: 19 step: 24, loss is 8.413565228693187e-05\n",
      "epoch: 19 step: 44, loss is 9.596852760296315e-05\n",
      "epoch: 19 step: 64, loss is 2.2403441107599065e-05\n",
      "epoch: 19 step: 84, loss is 2.0674659026553854e-05\n",
      "epoch: 19 step: 104, loss is 3.694595579872839e-05\n",
      "epoch: 19 step: 124, loss is 0.02107689157128334\n",
      "epoch: 19 step: 144, loss is 0.0011889981105923653\n",
      "epoch: 19 step: 164, loss is 0.002791450824588537\n",
      "epoch: 19 step: 184, loss is 0.00011776613246183842\n",
      "epoch: 19 step: 204, loss is 3.373464642209001e-05\n",
      "epoch: 20 step: 12, loss is 5.191826130612753e-05\n",
      "epoch: 20 step: 32, loss is 3.585690137697384e-05\n",
      "epoch: 20 step: 52, loss is 6.036771446815692e-05\n",
      "epoch: 20 step: 72, loss is 0.00023859395878389478\n",
      "epoch: 20 step: 92, loss is 7.800769526511431e-05\n",
      "epoch: 20 step: 112, loss is 3.4799129934981465e-05\n",
      "epoch: 20 step: 132, loss is 0.0004742351302411407\n",
      "epoch: 20 step: 152, loss is 9.580209734849632e-05\n",
      "epoch: 20 step: 172, loss is 4.5080723793944344e-05\n",
      "epoch: 20 step: 192, loss is 2.4831710106809624e-05\n",
      "epoch: 20 step: 212, loss is 1.1660051313810982e-05\n",
      "epoch: 21 step: 20, loss is 2.4816865334287286e-05\n",
      "epoch: 21 step: 40, loss is 0.00014921394176781178\n",
      "epoch: 21 step: 60, loss is 6.9723668275401e-05\n",
      "epoch: 21 step: 80, loss is 0.00011869149602716789\n",
      "epoch: 21 step: 100, loss is 0.0002560416760388762\n",
      "epoch: 21 step: 120, loss is 4.5966447942191735e-05\n",
      "epoch: 21 step: 140, loss is 0.00018000195268541574\n",
      "epoch: 21 step: 160, loss is 5.630680971080437e-05\n",
      "epoch: 21 step: 180, loss is 0.0010396147845312953\n",
      "epoch: 21 step: 200, loss is 0.00031893071718513966\n",
      "epoch: 22 step: 8, loss is 0.0004899491323158145\n",
      "epoch: 22 step: 28, loss is 0.0001487638510297984\n",
      "epoch: 22 step: 48, loss is 0.00018408411415293813\n",
      "epoch: 22 step: 68, loss is 7.870747504057363e-05\n",
      "epoch: 22 step: 88, loss is 0.028352543711662292\n",
      "epoch: 22 step: 108, loss is 0.00013085658429190516\n",
      "epoch: 22 step: 128, loss is 0.001571387518197298\n",
      "epoch: 22 step: 148, loss is 5.901539043406956e-05\n",
      "epoch: 22 step: 168, loss is 6.782749551348388e-05\n",
      "epoch: 22 step: 188, loss is 6.205084355315194e-05\n",
      "epoch: 22 step: 208, loss is 2.878812847484369e-05\n",
      "epoch: 23 step: 16, loss is 8.638286089990288e-05\n",
      "epoch: 23 step: 36, loss is 0.00011975945380982012\n",
      "epoch: 23 step: 56, loss is 3.625176032073796e-05\n",
      "epoch: 23 step: 76, loss is 0.00010658350947778672\n",
      "epoch: 23 step: 96, loss is 8.011011232156307e-05\n",
      "epoch: 23 step: 116, loss is 3.18422207783442e-05\n",
      "epoch: 23 step: 136, loss is 3.001759250764735e-05\n",
      "epoch: 23 step: 156, loss is 0.0003213107993360609\n",
      "epoch: 23 step: 176, loss is 1.689024065854028e-05\n",
      "epoch: 23 step: 196, loss is 2.3632463125977665e-05\n",
      "epoch: 24 step: 4, loss is 1.5288382201106288e-05\n",
      "epoch: 24 step: 24, loss is 5.788739144918509e-05\n",
      "epoch: 24 step: 44, loss is 3.452454984653741e-05\n",
      "epoch: 24 step: 64, loss is 1.7925856809597462e-05\n",
      "epoch: 24 step: 84, loss is 1.9095234165433794e-05\n",
      "epoch: 24 step: 104, loss is 1.742642416502349e-05\n",
      "epoch: 24 step: 124, loss is 0.00012116594007238746\n",
      "epoch: 24 step: 144, loss is 2.6490504751564004e-05\n",
      "epoch: 24 step: 164, loss is 2.3564380171592347e-05\n",
      "epoch: 24 step: 184, loss is 0.00016883385251276195\n",
      "epoch: 24 step: 204, loss is 6.313709309324622e-05\n",
      "epoch: 25 step: 12, loss is 1.8290531443199143e-05\n",
      "epoch: 25 step: 32, loss is 6.696697528241202e-05\n",
      "epoch: 25 step: 52, loss is 1.0542516065470409e-05\n",
      "epoch: 25 step: 72, loss is 4.6089822717476636e-05\n",
      "epoch: 25 step: 92, loss is 0.0005294457660056651\n",
      "epoch: 25 step: 112, loss is 0.00029990595066919923\n",
      "epoch: 25 step: 132, loss is 1.9370612790226005e-05\n",
      "epoch: 25 step: 152, loss is 2.08979872695636e-05\n",
      "epoch: 25 step: 172, loss is 0.00010241684503853321\n",
      "epoch: 25 step: 192, loss is 2.1747227947344072e-05\n",
      "epoch: 25 step: 212, loss is 1.7307311281911097e-05\n",
      "epoch: 26 step: 20, loss is 3.8993563066469505e-05\n",
      "epoch: 26 step: 40, loss is 1.3671431588591076e-05\n",
      "epoch: 26 step: 60, loss is 3.035924964933656e-05\n",
      "epoch: 26 step: 80, loss is 7.246095628943294e-05\n",
      "epoch: 26 step: 100, loss is 3.281138197053224e-05\n",
      "epoch: 26 step: 120, loss is 2.3245098418556154e-05\n",
      "epoch: 26 step: 140, loss is 1.1637638635875192e-05\n",
      "epoch: 26 step: 160, loss is 1.2129386959713884e-05\n",
      "epoch: 26 step: 180, loss is 5.500615225173533e-05\n",
      "epoch: 26 step: 200, loss is 0.0005846212152391672\n",
      "epoch: 27 step: 8, loss is 7.845435902709141e-05\n",
      "epoch: 27 step: 28, loss is 0.0002707323874346912\n",
      "epoch: 27 step: 48, loss is 0.00012900325236842036\n",
      "epoch: 27 step: 68, loss is 0.00020599915296770632\n",
      "epoch: 27 step: 88, loss is 0.0018576487200334668\n",
      "epoch: 27 step: 108, loss is 0.9449849128723145\n",
      "epoch: 27 step: 128, loss is 0.11184568703174591\n",
      "epoch: 27 step: 148, loss is 0.004257534630596638\n",
      "epoch: 27 step: 168, loss is 0.0426877923309803\n",
      "epoch: 27 step: 188, loss is 0.017238974571228027\n",
      "epoch: 27 step: 208, loss is 0.020483218133449554\n",
      "epoch: 28 step: 16, loss is 0.018707910552620888\n",
      "epoch: 28 step: 36, loss is 0.17701737582683563\n",
      "epoch: 28 step: 56, loss is 0.0006228075944818556\n",
      "epoch: 28 step: 76, loss is 0.2059280276298523\n",
      "epoch: 28 step: 96, loss is 0.0023689805530011654\n",
      "epoch: 28 step: 116, loss is 0.17367465794086456\n",
      "epoch: 28 step: 136, loss is 0.24637892842292786\n",
      "epoch: 28 step: 156, loss is 1.4188417196273804\n",
      "epoch: 28 step: 176, loss is 0.48061391711235046\n",
      "epoch: 28 step: 196, loss is 0.010984119027853012\n",
      "epoch: 29 step: 4, loss is 0.0005418085493147373\n",
      "epoch: 29 step: 24, loss is 0.0002589639916550368\n",
      "epoch: 29 step: 44, loss is 0.0029470992740243673\n",
      "epoch: 29 step: 64, loss is 7.048572297208011e-05\n",
      "epoch: 29 step: 84, loss is 0.00047806790098547935\n",
      "epoch: 29 step: 104, loss is 3.0255705496529117e-05\n",
      "epoch: 29 step: 124, loss is 0.00015023825108073652\n",
      "epoch: 29 step: 144, loss is 6.415815005311742e-05\n",
      "epoch: 29 step: 164, loss is 1.8454218661645427e-05\n",
      "epoch: 29 step: 184, loss is 0.0005716613377444446\n",
      "epoch: 29 step: 204, loss is 0.00028063205536454916\n",
      "epoch: 30 step: 12, loss is 0.001993351150304079\n",
      "epoch: 30 step: 32, loss is 0.00022118217020761222\n",
      "epoch: 30 step: 52, loss is 0.007738193031400442\n",
      "epoch: 30 step: 72, loss is 0.2034609317779541\n",
      "epoch: 30 step: 92, loss is 0.0004058514896314591\n",
      "epoch: 30 step: 112, loss is 0.0007780523737892509\n",
      "epoch: 30 step: 132, loss is 0.004606315400451422\n",
      "epoch: 30 step: 152, loss is 0.001249047345481813\n",
      "epoch: 30 step: 172, loss is 0.0027122460305690765\n",
      "epoch: 30 step: 192, loss is 0.00038782088086009026\n",
      "epoch: 30 step: 212, loss is 0.00023079956008587033\n"
     ]
    }
   ],
   "source": [
    "trainer.train(30,train_loader,callbacks=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a83d24c-e603-4ec1-98f3-54f9ea7ee67f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T12:12:47.129722Z",
     "iopub.status.busy": "2024-06-26T12:12:47.129246Z",
     "iopub.status.idle": "2024-06-26T12:22:41.383942Z",
     "shell.execute_reply": "2024-06-26T12:22:41.382440Z",
     "shell.execute_reply.started": "2024-06-26T12:12:47.129679Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9428104575163399}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms.load_param_into_net(model, ms.load_checkpoint(ckpt_cb.latest_ckpt_file_name))\n",
    "trainer.eval(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
